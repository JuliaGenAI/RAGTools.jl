var documenterSearchIndex = {"docs":
[{"location":"api_reference/#RAGTools","page":"API Reference","title":"RAGTools","text":"","category":"section"},{"location":"api_reference/","page":"API Reference","title":"API Reference","text":"This is a meta-package exporting PromptingTools RAGTools sub-module and it's key dependencies to simplify the workflow. A simple quality of life improvement.","category":"page"},{"location":"api_reference/","page":"API Reference","title":"API Reference","text":"For details on how to use RAGTools see the manual.","category":"page"},{"location":"api_reference/","page":"API Reference","title":"API Reference","text":"","category":"page"},{"location":"api_reference/#RAGTools.AbstractCandidateChunks","page":"API Reference","title":"RAGTools.AbstractCandidateChunks","text":"AbstractCandidateChunks\n\nAbstract type for storing candidate chunks, ie, references to items in a AbstractChunkIndex.\n\nReturn type from find_closest and find_tags functions.\n\nRequired Fields\n\nindex_id::Symbol: the id of the index from which the candidates are drawn\npositions::Vector{Int}: the positions of the candidates in the index\nscores::Vector{Float32}: the similarity scores of the candidates from the query (higher is better)\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.AbstractChunkIndex","page":"API Reference","title":"RAGTools.AbstractChunkIndex","text":"AbstractChunkIndex <: AbstractDocumentIndex\n\nMain abstract type for storing document chunks and their embeddings. It also stores tags and sources for each chunk.\n\nRequired Fields\n\nid::Symbol: unique identifier of each index (to ensure we're using the right index with CandidateChunks)\nchunks::Vector{<:AbstractString}: underlying document chunks / snippets\nembeddings::Union{Nothing, Matrix{<:Real}}: for semantic search\ntags::Union{Nothing, AbstractMatrix{<:Bool}}: for exact search, filtering, etc. This is often a sparse matrix indicating which chunks have the given tag (see tag_vocab for the position lookup)\ntags_vocab::Union{Nothing, Vector{<:AbstractString}}: vocabulary for the tags matrix (each column in tags is one item in tags_vocab and rows are the chunks)\nsources::Vector{<:AbstractString}: sources of the chunks\nextras::Union{Nothing, AbstractVector}: additional data, eg, metadata, source code, etc.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.AbstractDocumentTermMatrix","page":"API Reference","title":"RAGTools.AbstractDocumentTermMatrix","text":"AbstractDocumentTermMatrix\n\nAbstract type for a document term matrix.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.AbstractGenerator","page":"API Reference","title":"RAGTools.AbstractGenerator","text":"AbstractGenerator <: AbstractGenerationMethod\n\nAbstract type for generating an answer with generate! (use to change the process / return type of generate).\n\nRequired Fields\n\ncontexter::AbstractContextBuilder: the context building method, dispatching `build_context!\nanswerer::AbstractAnswerer: the answer generation method, dispatching answer!\nrefiner::AbstractRefiner: the answer refining method, dispatching refine!\npostprocessor::AbstractPostprocessor: the postprocessing method, dispatching postprocess!\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.AbstractIndexBuilder","page":"API Reference","title":"RAGTools.AbstractIndexBuilder","text":"AbstractIndexBuilder\n\nAbstract type for building an index with build_index (use to change the process / return type of build_index).\n\nRequired Fields\n\nchunker::AbstractChunker: the chunking method, dispatching get_chunks\nembedder::AbstractEmbedder: the embedding method, dispatching get_embeddings\ntagger::AbstractTagger: the tagging method, dispatching get_tags\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.AbstractMultiIndex","page":"API Reference","title":"RAGTools.AbstractMultiIndex","text":"AbstractMultiIndex <: AbstractDocumentIndex\n\nExperimental abstract type for storing multiple document indexes. Not yet implemented.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.AbstractRetriever","page":"API Reference","title":"RAGTools.AbstractRetriever","text":"AbstractRetriever <: AbstractRetrievalMethod\n\nAbstract type for retrieving chunks from an index with retrieve (use to change the process / return type of retrieve).\n\nRequired Fields\n\nrephraser::AbstractRephraser: the rephrasing method, dispatching rephrase\nfinder::AbstractSimilarityFinder: the similarity search method, dispatching find_closest\nfilter::AbstractTagFilter: the tag matching method, dispatching find_tags\nreranker::AbstractReranker: the reranking method, dispatching rerank\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.AdvancedGenerator","page":"API Reference","title":"RAGTools.AdvancedGenerator","text":"AdvancedGenerator <: AbstractGenerator\n\nDefault implementation for generate!. It simply enumerates context snippets and runs aigenerate (no refinement).\n\nIt uses ContextEnumerator, SimpleAnswerer, SimpleRefiner, and NoPostprocessor as default contexter, answerer, refiner, and postprocessor.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.AdvancedRetriever","page":"API Reference","title":"RAGTools.AdvancedRetriever","text":"AdvancedRetriever <: AbstractRetriever\n\nDispatch for retrieve with advanced retrieval methods to improve result quality. Compared to SimpleRetriever, it adds rephrasing the query and reranking the results.\n\nFields\n\nrephraser::AbstractRephraser: the rephrasing method, dispatching rephrase - uses HyDERephraser\nembedder::AbstractEmbedder: the embedding method, dispatching get_embeddings (see Preparation Stage for more details) - uses BatchEmbedder\nprocessor::AbstractProcessor: the processor method, dispatching get_keywords (see Preparation Stage for more details) - uses NoProcessor\nfinder::AbstractSimilarityFinder: the similarity search method, dispatching find_closest - uses CosineSimilarity\ntagger::AbstractTagger: the tag generating method, dispatching get_tags (see Preparation Stage for more details) - uses NoTagger\nfilter::AbstractTagFilter: the tag matching method, dispatching find_tags - uses NoTagFilter\nreranker::AbstractReranker: the reranking method, dispatching rerank - uses CohereReranker\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.AllTagFilter","page":"API Reference","title":"RAGTools.AllTagFilter","text":"AllTagFilter <: AbstractTagFilter\n\nFinds the chunks that have ALL OF the specified tag(s). A method for find_tags.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.AnnotatedNode","page":"API Reference","title":"RAGTools.AnnotatedNode","text":"AnnotatedNode{T}  <: AbstractAnnotatedNode\n\nA node to add annotations to the generated answer in airag\n\nAnnotations can be: sources, scores, whether its supported or not by the context, etc.\n\nFields\n\ngroup_id::Int: Unique identifier for the same group of nodes (eg, different lines of the same code block)\nparent::Union{AnnotatedNode, Nothing}: Parent node that current node was built on\nchildren::Vector{AnnotatedNode}: Children nodes\n`score::\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.AnyTagFilter","page":"API Reference","title":"RAGTools.AnyTagFilter","text":"AnyTagFilter <: AbstractTagFilter\n\nFinds the chunks that have ANY OF the specified tag(s). A method for find_tags.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.BM25Similarity","page":"API Reference","title":"RAGTools.BM25Similarity","text":"BM25Similarity <: AbstractSimilarityFinder\n\nFinds the closest chunks to a query embedding by measuring the BM25 similarity between the query and the chunks' embeddings in binary form. A method for find_closest.\n\nReference: Wikipedia: BM25. Implementation follows: The Next Generation of Lucene Relevance.\n\nFields mimic the arguments of bm25.\n\nFields\n\nk1: The k1 parameter for BM25. Default is 1.2.\nb: The b parameter for BM25. Default is 0.75.\nnormalize: Whether to normalize the scores. Default is false.\nnormalize_max_tf: The maximum term frequency to normalize to. Default is 3.\nnormalize_min_doc_rel_length: The minimum document relative length to normalize to. Default is 1.0.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.BatchEmbedder","page":"API Reference","title":"RAGTools.BatchEmbedder","text":"BatchEmbedder <: AbstractEmbedder\n\nDefault embedder for get_embeddings functions. It passes individual documents to be embedded in chunks to aiembed.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.BinaryBatchEmbedder","page":"API Reference","title":"RAGTools.BinaryBatchEmbedder","text":"BinaryBatchEmbedder <: AbstractEmbedder\n\nSame as BatchEmbedder but reduces the embeddings matrix to a binary form (eg, BitMatrix). Defines a method for get_embeddings.\n\nReference: HuggingFace: Embedding Quantization.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.BinaryCosineSimilarity","page":"API Reference","title":"RAGTools.BinaryCosineSimilarity","text":"BinaryCosineSimilarity <: AbstractSimilarityFinder\n\nFinds the closest chunks to a query embedding by measuring the Hamming distance AND cosine similarity between the query and the chunks' embeddings in binary form. A method for find_closest.\n\nIt follows the two-pass approach:\n\nFirst pass: Hamming distance in binary form to get the top_k * rescore_multiplier (ie, more than top_k) candidates.\nSecond pass: Rescore the candidates with float embeddings and return the top_k.\n\nReference: HuggingFace: Embedding Quantization.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.BitPackedBatchEmbedder","page":"API Reference","title":"RAGTools.BitPackedBatchEmbedder","text":"BitPackedBatchEmbedder <: AbstractEmbedder\n\nSame as BatchEmbedder but reduces the embeddings matrix to a binary form packed in UInt64 (eg, BitMatrix.chunks). Defines a method for get_embeddings.\n\nSee also utilities pack_bits and unpack_bits to move between packed/non-packed binary forms.\n\nReference: HuggingFace: Embedding Quantization.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.BitPackedCosineSimilarity","page":"API Reference","title":"RAGTools.BitPackedCosineSimilarity","text":"BitPackedCosineSimilarity <: AbstractSimilarityFinder\n\nFinds the closest chunks to a query embedding by measuring the Hamming distance AND cosine similarity between the query and the chunks' embeddings in binary form. A method for find_closest.\n\nThe difference to BinaryCosineSimilarity is that the binary values are packed into UInt64, which is more efficient.\n\nReference: HuggingFace: Embedding Quantization. Implementation of hamming_distance is based on TinyRAG.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.CandidateChunks","page":"API Reference","title":"RAGTools.CandidateChunks","text":"CandidateChunks\n\nA struct for storing references to chunks in the given index (identified by index_id)  called positions and scores holding the strength of similarity (=1 is the highest,  most similar). It's the result of the retrieval stage of RAG.\n\nFields\n\nindex_id::Symbol: the id of the index from which the candidates are drawn\npositions::Vector{Int}: the positions of the candidates in the index (ie, 5 \n\nrefers to the 5th chunk in the index - `chunks(index)[5]`)\n\nscores::Vector{Float32}: the similarity scores of the candidates from the query (higher is better)\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.ChunkEmbeddingsIndex","page":"API Reference","title":"RAGTools.ChunkEmbeddingsIndex","text":"ChunkEmbeddingsIndex\n\nMain struct for storing document chunks and their embeddings. It also stores tags  and sources for each chunk.\n\nPreviously, this struct was called ChunkIndex.\n\nFields\n\nid::Symbol: unique identifier of each index (to ensure we're using the right index with CandidateChunks)\nchunks::Vector{<:AbstractString}: underlying document chunks / snippets\nembeddings::Union{Nothing, Matrix{<:Real}}: for semantic search\ntags::Union{Nothing, AbstractMatrix{<:Bool}}: for exact search, filtering, etc.    This is often a sparse matrix indicating which chunks have the given tag    (see tag_vocab for the position lookup)\ntags_vocab::Union{Nothing, Vector{<:AbstractString}}: vocabulary for the tags    matrix (each column in tags is one item in tags_vocab and rows are the chunks)\nsources::Vector{<:AbstractString}: sources of the chunks\nextras::Union{Nothing, AbstractVector}: additional data, eg, metadata, source code, etc.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.ChunkKeywordsIndex","page":"API Reference","title":"RAGTools.ChunkKeywordsIndex","text":"ChunkKeywordsIndex\n\nStruct for storing chunks of text and associated keywords for BM25 similarity search.\n\nFields\n\nid::Symbol: unique identifier of each index (to ensure we're using the right    index with CandidateChunks)\nchunks::Vector{<:AbstractString}: underlying document chunks / snippets\nchunkdata::Union{Nothing, AbstractMatrix{<:Real}}: for similarity search,    assumed to be DocumentTermMatrix\ntags::Union{Nothing, AbstractMatrix{<:Bool}}: for exact search, filtering, etc.    This is often a sparse matrix indicating which chunks have the given tag    (see tag_vocab for the position lookup)\ntags_vocab::Union{Nothing, Vector{<:AbstractString}}: vocabulary for the tags    matrix (each column in tags is one item in tags_vocab and rows are the chunks)\nsources::Vector{<:AbstractString}: sources of the chunks\nextras::Union{Nothing, AbstractVector}: additional data, eg, metadata, source code, etc.\n\nExample\n\nWe can easily create a keywords-based index from a standard embeddings-based index.\n\n\n# Let's assume we have a standard embeddings-based index\nindex = build_index(SimpleIndexer(), texts; chunker_kwargs = (; max_length=10))\n\n# Creating an additional index for keyword-based search (BM25), is as simple as\nindex_keywords = ChunkKeywordsIndex(index)\n\n# We can immediately create a MultiIndex (a hybrid index holding both indices)\nmulti_index = MultiIndex([index, index_keywords])\n\n\nYou can also build the index via build_index\n\n# given some sentences and sources\nindex_keywords = build_index(KeywordsIndexer(), sentences; chunker_kwargs=(; sources))\n\n# Retrive closest chunks with\nretriever = SimpleBM25Retriever()\nresult = retrieve(retriever, index_keywords, \"What are the best practices for parallel computing in Julia?\")\nresult.context\n\nIf you want to use airag, don't forget to specify the config to make sure keywords  are processed (ie, tokenized) and that BM25 is used for searching candidates\n\ncfg = RAGConfig(; retriever = SimpleBM25Retriever());\nairag(cfg, index_keywords;\n\tquestion = \"What are the best practices for parallel computing in Julia?\")\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.ChunkKeywordsIndex-Tuple{RAGTools.AbstractProcessor, ChunkEmbeddingsIndex}","page":"API Reference","title":"RAGTools.ChunkKeywordsIndex","text":"ChunkKeywordsIndex(\n\t[processor::AbstractProcessor=KeywordsProcessor(),] index::ChunkEmbeddingsIndex; verbose::Int = 1,\n\tindex_id = gensym(\"ChunkKeywordsIndex\"), processor_kwargs...)\n\nConvenience method to quickly create a ChunkKeywordsIndex from an existing ChunkEmbeddingsIndex.\n\nExample\n\n\n# Let's assume we have a standard embeddings-based index\nindex = build_index(SimpleIndexer(), texts; chunker_kwargs = (; max_length=10))\n\n# Creating an additional index for keyword-based search (BM25), is as simple as\nindex_keywords = ChunkKeywordsIndex(index)\n\n# We can immediately create a MultiIndex (a hybrid index holding both indices)\nmulti_index = MultiIndex([index, index_keywords])\n\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.CohereReranker","page":"API Reference","title":"RAGTools.CohereReranker","text":"CohereReranker <: AbstractReranker\n\nRerank strategy using the Cohere Rerank API. Requires an API key. A method for rerank.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.ContextEnumerator","page":"API Reference","title":"RAGTools.ContextEnumerator","text":"ContextEnumerator <: AbstractContextBuilder\n\nDefault method for build_context! method. It simply enumerates the context snippets around each position in candidates. When possibly, it will add surrounding chunks (from the same source).\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.CosineSimilarity","page":"API Reference","title":"RAGTools.CosineSimilarity","text":"CosineSimilarity <: AbstractSimilarityFinder\n\nFinds the closest chunks to a query embedding by measuring the cosine similarity between the query and the chunks' embeddings. A method for find_closest (see the docstring for more details and usage example).\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.DocumentTermMatrix","page":"API Reference","title":"RAGTools.DocumentTermMatrix","text":"DocumentTermMatrix{T<:AbstractString}\n\nA sparse matrix of term frequencies and document lengths to allow calculation of BM25 similarity scores.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.FileChunker","page":"API Reference","title":"RAGTools.FileChunker","text":"FileChunker <: AbstractChunker\n\nChunker when you provide file paths to get_chunks functions.\n\nIe, the inputs will be validated first (eg, file exists, etc) and then read into memory.\n\nSet as default chunker in get_chunks functions.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.FlashRanker","page":"API Reference","title":"RAGTools.FlashRanker","text":"FlashRanker <: AbstractReranker\n\nRerank strategy using the package FlashRank.jl and local models. A method for rerank.\n\nYou must first import the FlashRank.jl package. To automatically download any required models, set your  ENV[\"DATADEPS_ALWAYS_ACCEPT\"] = true (see DataDeps for more details).\n\nExample\n\nusing FlashRank\n\n# Wrap the model to be a valid Ranker recognized by RAGTools\n# It will be provided to the airag/rerank function to avoid instantiating it on every call\nreranker = FlashRank.RankerModel(:mini) |> FlashRanker\n# You can choose :tiny or :mini\n\n## Apply to the pipeline configuration, eg, \ncfg = RAGConfig(; retriever = AdvancedRetriever(; reranker))\n\n# Ask a question (assumes you have some `index`)\nquestion = \"What are the best practices for parallel computing in Julia?\"\nresult = airag(cfg, index; question, return_all = true)\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.HTMLStyler","page":"API Reference","title":"RAGTools.HTMLStyler","text":"HTMLStyler\n\nDefines styling via classes (attribute class) and styles (attribute style) for HTML formatting of AbstractAnnotatedNode\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.HyDERephraser","page":"API Reference","title":"RAGTools.HyDERephraser","text":"HyDERephraser <: AbstractRephraser\n\nRephraser implemented using the provided AI Template (eg, ...) and standard chat model. A method for rephrase.\n\nIt uses a prompt-based rephrasing method called HyDE (Hypothetical Document Embedding), where instead of looking for an embedding of the question,  we look for the documents most similar to a synthetic passage that would be a good answer to our question.\n\nReference: Arxiv paper.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.JudgeAllScores","page":"API Reference","title":"RAGTools.JudgeAllScores","text":"final_rating is the average of all scoring criteria. Explain the final_rating in rationale\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.JudgeRating","page":"API Reference","title":"RAGTools.JudgeRating","text":"Provide the final_rating between 1-5. Provide the rationale for it.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.KeywordsIndexer","page":"API Reference","title":"RAGTools.KeywordsIndexer","text":"KeywordsIndexer <: AbstractIndexBuilder\n\nKeyword-based index (BM25) to be returned by build_index.\n\nIt uses TextChunker, KeywordsProcessor, and NoTagger as default chunker, processor, and tagger.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.KeywordsProcessor","page":"API Reference","title":"RAGTools.KeywordsProcessor","text":"KeywordsProcessor <: AbstractProcessor\n\nDefault keywords processor for get_keywords functions. It normalizes the documents, tokenizes them and builds a DocumentTermMatrix.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.MultiCandidateChunks","page":"API Reference","title":"RAGTools.MultiCandidateChunks","text":"MultiCandidateChunks\n\nA struct for storing references to multiple sets of chunks across different indices.  Each set of chunks is identified by an index_id in index_ids, with corresponding  positions in the index and scores indicating the strength of similarity.\n\nThis struct is useful for scenarios where candidates are drawn from multiple indices,  and there is a need to keep track of which candidates came from which index.\n\nFields\n\nindex_ids::Vector{Symbol}: the ids of the indices from which the candidates are drawn\npositions::Vector{TP}: the positions of the candidates in their respective indices\nscores::Vector{TD}: the similarity scores of the candidates from the query\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.MultiFinder","page":"API Reference","title":"RAGTools.MultiFinder","text":"MultiFinder <: AbstractSimilarityFinder\n\nComposite finder for MultiIndex where we want to set multiple finders for each index. A method for find_closest. Positions correspond to indexes(::MultiIndex).\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.MultiIndex","page":"API Reference","title":"RAGTools.MultiIndex","text":"MultiIndex\n\nComposite index that stores multiple ChunkIndex objects and their embeddings.\n\nFields\n\nid::Symbol: unique identifier of each index (to ensure we're using the right index with CandidateChunks)\nindexes::Vector{<:AbstractChunkIndex}: the indexes to be combined\n\nUse accesor indexes to access the individual indexes.\n\nExamples\n\nWe can create a MultiIndex from a vector of AbstractChunkIndex objects.\n\nindex = build_index(SimpleIndexer(), texts; chunker_kwargs = (; sources))\nindex_keywords = ChunkKeywordsIndex(index) # same chunks as above but adds BM25 instead of embeddings\n\nmulti_index = MultiIndex([index, index_keywords])\n\nTo use airag with different types of indices, we need to specify how to find the closest items for each index\n\n# Cosine similarity for embeddings and BM25 for keywords, same order as indexes in MultiIndex\nfinder = RT.MultiFinder([RT.CosineSimilarity(), RT.BM25Similarity()])\n\n# Notice that we add `processor` to make sure keywords are processed (ie, tokenized) as well\ncfg = RAGConfig(; retriever = SimpleRetriever(; processor = RT.KeywordsProcessor(), finder))\n\n# Ask questions\nmsg = airag(cfg, multi_index; question = \"What are the best practices for parallel computing in Julia?\")\npprint(msg) # prettify the answer\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.NoEmbedder","page":"API Reference","title":"RAGTools.NoEmbedder","text":"NoEmbedder <: AbstractEmbedder\n\nNo-op embedder for get_embeddings functions. It returns nothing.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.NoPostprocessor","page":"API Reference","title":"RAGTools.NoPostprocessor","text":"NoPostprocessor <: AbstractPostprocessor\n\nDefault method for postprocess! method. A passthrough option that returns the result without any changes.\n\nOverload this method to add custom postprocessing steps, eg, logging, saving conversations to disk, etc.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.NoProcessor","page":"API Reference","title":"RAGTools.NoProcessor","text":"NoProcessor <: AbstractProcessor\n\nNo-op processor for get_keywords functions. It returns the inputs as is.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.NoRefiner","page":"API Reference","title":"RAGTools.NoRefiner","text":"NoRefiner <: AbstractRefiner\n\nDefault method for refine! method. A passthrough option that returns the result.answer without any changes.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.NoRephraser","page":"API Reference","title":"RAGTools.NoRephraser","text":"NoRephraser <: AbstractRephraser\n\nNo-op implementation for rephrase, which simply passes the question through.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.NoReranker","page":"API Reference","title":"RAGTools.NoReranker","text":"NoReranker <: AbstractReranker\n\nNo-op implementation for rerank, which simply passes the candidate chunks through.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.NoTagFilter","page":"API Reference","title":"RAGTools.NoTagFilter","text":"NoTagFilter <: AbstractTagFilter\n\nNo-op implementation for find_tags, which simply returns all chunks.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.NoTagger","page":"API Reference","title":"RAGTools.NoTagger","text":"NoTagger <: AbstractTagger\n\nNo-op tagger for get_tags functions. It returns (nothing, nothing).\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.OpenTagger","page":"API Reference","title":"RAGTools.OpenTagger","text":"OpenTagger <: AbstractTagger\n\nTagger for get_tags functions, which generates possible tags for each chunk via aiextract.  You can customize it via prompt template (default: :RAGExtractMetadataShort), but it's quite open-ended (ie, AI decides the possible tags).\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.PassthroughTagger","page":"API Reference","title":"RAGTools.PassthroughTagger","text":"PassthroughTagger <: AbstractTagger\n\nTagger for get_tags functions, which passes tags directly as Vector of Vectors of strings (ie, tags[i] is the tags for docs[i]).\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.RAGConfig","page":"API Reference","title":"RAGTools.RAGConfig","text":"RAGConfig <: AbstractRAGConfig\n\nDefault configuration for RAG. It uses SimpleIndexer, SimpleRetriever, and SimpleGenerator as default components. Provided as the first argument in airag.\n\nTo customize the components, replace corresponding fields for each step of the RAG pipeline (eg, use subtypes(AbstractIndexBuilder) to find the available options).\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.RAGResult","page":"API Reference","title":"RAGTools.RAGResult","text":"RAGResult\n\nA struct for debugging RAG answers. It contains the question, answer, context,  and the candidate chunks at each step of the RAG pipeline.\n\nThink of the flow as question -> rephrased_questions -> answer -> final_answer  with the context and candidate chunks helping along the way.\n\nFields\n\nquestion::AbstractString: the original question\nrephrased_questions::Vector{<:AbstractString}: a vector of rephrased questions (eg, HyDe, Multihop, etc.)\nanswer::AbstractString: the generated answer\nfinal_answer::AbstractString: the refined final answer (eg, after CorrectiveRAG), \n\nalso considered the FINAL answer (it must be always available)\n\ncontext::Vector{<:AbstractString}: the context used for retrieval (ie, the vector \n\nof chunks and their surrounding window if applicable)\n\nsources::Vector{<:AbstractString}: the sources of the context (for the original matched chunks)\nemb_candidates::CandidateChunks: the candidate chunks from the embedding index (from find_closest)\ntag_candidates::Union{Nothing, CandidateChunks}: the candidate chunks from the tag index (from find_tags)\nfiltered_candidates::CandidateChunks: the filtered candidate chunks (intersection \n\nof `emb_candidates` and `tag_candidates`)\n\nreranked_candidates::CandidateChunks: the reranked candidate chunks (from rerank)\nconversations::Dict{Symbol,Vector{<:AbstractMessage}}: the conversation history for \n\nAI steps of the RAG pipeline, use keys that correspond to the function names, eg, `:answer` or `:refine`\n\nSee also: pprint (pretty printing), annotate_support (for annotating the answer)\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.RankGPTReranker","page":"API Reference","title":"RAGTools.RankGPTReranker","text":"RankGPTReranker <: AbstractReranker\n\nRerank strategy using the RankGPT algorithm (calling LLMs). A method for rerank.\n\nReference\n\n[1] Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents by W. Sun et al. [2] RankGPT Github\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.RankGPTResult","page":"API Reference","title":"RAGTools.RankGPTResult","text":"RankGPTResult\n\nResults from the RankGPT algorithm.\n\nFields\n\nquestion::String: The question that was asked.\nchunks::AbstractVector{T}: The chunks that were ranked (=context).\npositions::Vector{Int}: The ranking of the chunks (referring to the chunks).\nelapsed::Float64: The time it took to rank the chunks.\ncost::Float64: The cumulative cost of the ranking.\ntokens::Int: The cumulative number of tokens used in the ranking.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.ReciprocalRankFusionReranker","page":"API Reference","title":"RAGTools.ReciprocalRankFusionReranker","text":"ReciprocalRankFusionReranker <: AbstractReranker\n\nRerank strategy using the reciprocal rank fusion algorithm for simple cases with embeddings and keywords indices referring to the same chunks.  A dispatch type for rerank.\n\n!! To be used with MultiIndex that contains embeddings and keywords indices referring to the same chunks.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.SimpleAnswerer","page":"API Reference","title":"RAGTools.SimpleAnswerer","text":"SimpleAnswerer <: AbstractAnswerer\n\nDefault method for answer! method. Generates an answer using the aigenerate function with the provided context and question.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.SimpleBM25Retriever","page":"API Reference","title":"RAGTools.SimpleBM25Retriever","text":"SimpleBM25Retriever <: AbstractRetriever\n\nKeyword-based implementation for retrieve. It does a simple similarity search via BM25Similarity and returns the results.\n\nMake sure to use consistent processor and tagger with the Preparation Stage (build_index)!\n\nFields\n\nrephraser::AbstractRephraser: the rephrasing method, dispatching rephrase - uses NoRephraser\nembedder::AbstractEmbedder: the embedding method, dispatching get_embeddings (see Preparation Stage for more details) - uses NoEmbedder\nprocessor::AbstractProcessor: the processor method, dispatching get_keywords (see Preparation Stage for more details) - uses KeywordsProcessor\nfinder::AbstractSimilarityFinder: the similarity search method, dispatching find_closest - uses CosineSimilarity\ntagger::AbstractTagger: the tag generating method, dispatching get_tags (see Preparation Stage for more details) - uses NoTagger\nfilter::AbstractTagFilter: the tag matching method, dispatching find_tags - uses NoTagFilter\nreranker::AbstractReranker: the reranking method, dispatching rerank - uses NoReranker\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.SimpleGenerator","page":"API Reference","title":"RAGTools.SimpleGenerator","text":"SimpleGenerator <: AbstractGenerator\n\nDefault implementation for generate. It simply enumerates context snippets and runs aigenerate (no refinement).\n\nIt uses ContextEnumerator, SimpleAnswerer, NoRefiner, and NoPostprocessor as default contexter, answerer, refiner, and postprocessor.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.SimpleIndexer","page":"API Reference","title":"RAGTools.SimpleIndexer","text":"SimpleIndexer <: AbstractIndexBuilder\n\nDefault implementation for build_index.\n\nIt uses TextChunker, BatchEmbedder, and NoTagger as default chunker, embedder, and tagger.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.SimpleRefiner","page":"API Reference","title":"RAGTools.SimpleRefiner","text":"SimpleRefiner <: AbstractRefiner\n\nRefines the answer using the same context previously provided via the provided prompt template. A method for refine!.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.SimpleRephraser","page":"API Reference","title":"RAGTools.SimpleRephraser","text":"SimpleRephraser <: AbstractRephraser\n\nRephraser implemented using the provided AI Template (eg, ...) and standard chat model. A method for rephrase.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.SimpleRetriever","page":"API Reference","title":"RAGTools.SimpleRetriever","text":"SimpleRetriever <: AbstractRetriever\n\nDefault implementation for retrieve function. It does a simple similarity search via CosineSimilarity and returns the results.\n\nMake sure to use consistent embedder and tagger with the Preparation Stage (build_index)!\n\nFields\n\nrephraser::AbstractRephraser: the rephrasing method, dispatching rephrase - uses NoRephraser\nembedder::AbstractEmbedder: the embedding method, dispatching get_embeddings (see Preparation Stage for more details) - uses BatchEmbedder\nprocessor::AbstractProcessor: the processor method, dispatching get_keywords (see Preparation Stage for more details) - uses NoProcessor\nfinder::AbstractSimilarityFinder: the similarity search method, dispatching find_closest - uses CosineSimilarity\ntagger::AbstractTagger: the tag generating method, dispatching get_tags (see Preparation Stage for more details) - uses NoTagger\nfilter::AbstractTagFilter: the tag matching method, dispatching find_tags - uses NoTagFilter\nreranker::AbstractReranker: the reranking method, dispatching rerank - uses NoReranker\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.Styler","page":"API Reference","title":"RAGTools.Styler","text":"Styler\n\nDefines styling keywords for printstyled for each AbstractAnnotatedNode\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.SubChunkIndex","page":"API Reference","title":"RAGTools.SubChunkIndex","text":"SubChunkIndex\n\nA view of the parent index with respect to the chunks (and chunk-aligned fields).  All methods and accessors working for AbstractChunkIndex also work for SubChunkIndex. It does not yet work for MultiIndex.\n\nFields\n\nparent::AbstractChunkIndex: the parent index from which the chunks are drawn    (always the original index, never a view)\npositions::Vector{Int}: the positions of the chunks in the parent index (always    refers to original PARENT index, even if we create a view of the view)\n\nExample\n\ncc = CandidateChunks(index.id, 1:10)\nsub_index = @view(index[cc])\n\nYou can use SubChunkIndex to access chunks or sources (and other fields) from a parent index, eg,\n\nRT.chunks(sub_index)\nRT.sources(sub_index)\nRT.chunkdata(sub_index) # slice of embeddings\nRT.embeddings(sub_index) # slice of embeddings\nRT.tags(sub_index) # slice of tags\nRT.tags_vocab(sub_index) # unchanged, identical to parent version\nRT.extras(sub_index) # slice of extras\n\nAccess the parent index that the positions correspond to\n\nparent(sub_index)\nRT.positions(sub_index)\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.SubDocumentTermMatrix","page":"API Reference","title":"RAGTools.SubDocumentTermMatrix","text":"SubDocumentTermMatrix\n\nA partial view of a DocumentTermMatrix, tf is MATERIALIZED for performance and fewer allocations.\"\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.TavilySearchRefiner","page":"API Reference","title":"RAGTools.TavilySearchRefiner","text":"TavilySearchRefiner <: AbstractRefiner\n\nRefines the answer by executing a web search using the Tavily API. This method aims to enhance the answer's accuracy and relevance by incorporating information retrieved from the web. A method for refine!.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.TextChunker","page":"API Reference","title":"RAGTools.TextChunker","text":"TextChunker <: AbstractChunker\n\nChunker when you provide text to get_chunks functions. Inputs are directly chunked\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#RAGTools.TrigramAnnotater","page":"API Reference","title":"RAGTools.TrigramAnnotater","text":"TrigramAnnotater\n\nAnnotation method where we score answer versus each context based on word-level trigrams that match.\n\nIt's very simple method (and it can loose some semantic meaning in longer sequences like negative), but it works reasonably well for both text and code.\n\n\n\n\n\n","category":"type"},{"location":"api_reference/#StructTypes.StructType-Tuple{Type{RAGResult}}","page":"API Reference","title":"StructTypes.StructType","text":"StructTypes.StructType(::Type{RAGResult})\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#Base.:==-Tuple{MultiIndex, MultiIndex}","page":"API Reference","title":"Base.:==","text":"Base.var\"==\"(i1::MultiIndex, i2::MultiIndex)\n\nCheck that each index has a counterpart in the other MultiIndex.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#Base.:==-Tuple{RAGTools.AbstractDocumentTermMatrix, RAGTools.AbstractDocumentTermMatrix}","page":"API Reference","title":"Base.:==","text":"Base.var\"==\"(dtm1::AbstractDocumentTermMatrix, dtm2::AbstractDocumentTermMatrix) = false\n\nCheck if two AbstractDocumentTermMatrix objects are equal.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#Base.:==-Union{Tuple{T}, Tuple{T, T}} where T<:RAGTools.AbstractRAGResult","page":"API Reference","title":"Base.:==","text":"Base.var\"==\"(r1::T, r2::T) where {T <: AbstractRAGResult}\n\nTwo RAGResult objects are equal if all their fields are equal.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#Base.copy-Tuple{T} where T<:RAGTools.AbstractRAGResult","page":"API Reference","title":"Base.copy","text":"Base.copy(r::T) where {T <: AbstractRAGResult}\n\nCopy a RAGResult object by deep copying all its fields.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#Base.getindex-Tuple{RAGTools.AbstractDocumentIndex, RAGTools.AbstractCandidateChunks, Symbol}","page":"API Reference","title":"Base.getindex","text":"Base.getindex\n\nGet the field of a candidate chunk from an index.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#Base.hcat-Tuple{RAGTools.AbstractDocumentTermMatrix, RAGTools.AbstractDocumentTermMatrix}","page":"API Reference","title":"Base.hcat","text":"Base.hcat(d1::AbstractDocumentTermMatrix, d2::AbstractDocumentTermMatrix)\n\nConcatenate two AbstractDocumentTermMatrix objects horizontally.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#Base.parent-Tuple{RAGTools.AbstractDocumentTermMatrix}","page":"API Reference","title":"Base.parent","text":"Base.parent(dtm::AbstractDocumentTermMatrix)\n\nThe parent of an AbstractDocumentTermMatrix is itself.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#Base.show-Tuple{IO, Union{RAGTools.AbstractCandidateChunks, RAGTools.AbstractDocumentIndex, RAGTools.AbstractRAGResult}}","page":"API Reference","title":"Base.show","text":"Base.show(io::IO,\n\tt::Union{AbstractDocumentIndex, AbstractCandidateChunks, AbstractRAGResult})\n\nStructured show method for easier reading (each kwarg on a new line)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#Base.view-Tuple{RAGTools.AbstractDocumentIndex, RAGTools.AbstractCandidateChunks}","page":"API Reference","title":"Base.view","text":"Base.view\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#Base.view-Tuple{RAGTools.SubDocumentTermMatrix, AbstractVector{<:Integer}, Colon}","page":"API Reference","title":"Base.view","text":"Base.view(dtm::SubDocumentTermMatrix, doc_idx::AbstractVector{<:Integer}, token_idx::Colon)\n\nCreate a view of a SubDocumentTermMatrix for a specific document index and all tokens.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#JSON3.read-Tuple{AbstractString, Type{RAGResult}}","page":"API Reference","title":"JSON3.read","text":"JSON3.read(path::AbstractString, ::Type{RAGResult})\n\nRead a RAGResult object from a JSON file.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PromptingTools.last_message-Tuple{RAGResult}","page":"API Reference","title":"PromptingTools.last_message","text":"PT.last_message(result::RAGResult)\n\nExtract the last message from the RAGResult for consistency with AICall / Message vectors.  It looks for final_answer first, then answer fields in the conversations dictionary.  Returns nothing if not found.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PromptingTools.last_output-Tuple{RAGResult}","page":"API Reference","title":"PromptingTools.last_output","text":"PT.last_output(result::RAGResult)\n\nExtracts the last output (generated text answer) from the RAGResult for consistency  with AICall / Message vectors.\n\nSee also: PT.last_message\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PromptingTools.pprint-Tuple{IO, RAGTools.AbstractAnnotatedNode}","page":"API Reference","title":"PromptingTools.pprint","text":"PromptingTools.pprint(\n\tio::IO, node::AbstractAnnotatedNode;\n\ttext_width::Int = displaysize(io)[2], add_newline::Bool = true)\n\nPretty print the node to the io stream, including all its children\n\nSupports only node.style::Styler for now.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#PromptingTools.pprint-Tuple{IO, RAGTools.AbstractRAGResult}","page":"API Reference","title":"PromptingTools.pprint","text":"PT.pprint(\n\tio::IO, r::AbstractRAGResult; add_context::Bool = false,\n\ttext_width::Int = displaysize(io)[2], annotater_kwargs...)\n\nPretty print the RAG result r to the given io stream. \n\nIf add_context is true, the context will be printed as well. The text_width  parameter can be used to control the width of the output.\n\nYou can provide additional keyword arguments to the annotater, eg, add_sources,  add_scores, min_score, etc. See annotate_support for more details.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.add_node_metadata!-Tuple{TrigramAnnotater, RAGTools.AnnotatedNode}","page":"API Reference","title":"RAGTools.add_node_metadata!","text":"add_node_metadata!(annotater::TrigramAnnotater,\n\troot::AnnotatedNode; add_sources::Bool = true, add_scores::Bool = true,\n\tsources::Union{Nothing, AbstractVector{<:AbstractString}} = nothing)\n\nAdds metadata to the children of root. Metadata includes sources and scores, if requested.\n\nOptionally, it can add a list of sources at the end of the printed text.\n\nThe metadata is added by inserting new nodes in the root children list (with no children of its own to be printed out).\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.airag-Tuple{RAGTools.AbstractRAGConfig, RAGTools.AbstractDocumentIndex}","page":"API Reference","title":"RAGTools.airag","text":"airag(cfg::AbstractRAGConfig, index::AbstractDocumentIndex;\n\tquestion::AbstractString,\n\tverbose::Integer = 1, return_all::Bool = false,\n\tapi_kwargs::NamedTuple = NamedTuple(),\n\tretriever::AbstractRetriever = cfg.retriever,\n\tretriever_kwargs::NamedTuple = NamedTuple(),\n\tgenerator::AbstractGenerator = cfg.generator,\n\tgenerator_kwargs::NamedTuple = NamedTuple(),\n\tcost_tracker = Threads.Atomic{Float64}(0.0))\n\nHigh-level wrapper for Retrieval-Augmented Generation (RAG), it combines together the retrieve and generate! steps which you can customize if needed.\n\nThe simplest version first finds the relevant chunks in index for the question and then sends these chunks to the AI model to help with generating a response to the question.\n\nTo customize the components, replace the types (retriever, generator) of the corresponding step of the RAG pipeline - or go into sub-routines within the steps. Eg, use subtypes(AbstractRetriever) to find the available options.\n\nArguments\n\ncfg::AbstractRAGConfig: The configuration for the RAG pipeline. Defaults to RAGConfig(), where you can swap sub-types to customize the pipeline.\nindex::AbstractDocumentIndex: The chunk index to search for relevant text.\nquestion::AbstractString: The question to be answered.\nreturn_all::Bool: If true, returns the details used for RAG along with the response.\nverbose::Integer: If >0, enables verbose logging. The higher the number, the more nested functions will log.\napi_kwargs: API parameters that will be forwarded to ALL of the API calls (aiembed, aigenerate, and aiextract).\nretriever::AbstractRetriever: The retriever to use for finding relevant chunks. Defaults to cfg.retriever, eg, SimpleRetriever (with no question rephrasing).\nretriever_kwargs::NamedTuple: API parameters that will be forwarded to the retriever call. Examples of important ones:\n\n- `top_k::Int`: Number of top candidates to retrieve based on embedding similarity.\n- `top_n::Int`: Number of candidates to return after reranking.\n- `tagger::AbstractTagger`: Tagger to use for tagging the chunks. Defaults to `NoTagger()`.\n- `tagger_kwargs::NamedTuple`: API parameters that will be forwarded to the `tagger` call. You could provide the explicit tags directly with `PassthroughTagger` and `tagger_kwargs = (; tags = [\"tag1\", \"tag2\"])`.\n\ngenerator::AbstractGenerator: The generator to use for generating the answer. Defaults to cfg.generator, eg, SimpleGenerator.\ngenerator_kwargs::NamedTuple: API parameters that will be forwarded to the generator call. Examples of important ones:\n\n- `answerer_kwargs::NamedTuple`: API parameters that will be forwarded to the `answerer` call. Examples:\n\t- `model`: The model to use for generating the answer. Defaults to `PT.MODEL_CHAT`.\n\t- `template`: The template to use for the `aigenerate` function. Defaults to `:RAGAnswerFromContext`.\n- `refiner::AbstractRefiner`: The method to use for refining the answer. Defaults to `generator.refiner`, eg, `NoRefiner`.\n- `refiner_kwargs::NamedTuple`: API parameters that will be forwarded to the `refiner` call.\n\t- `model`: The model to use for generating the answer. Defaults to `PT.MODEL_CHAT`.\n\t- `template`: The template to use for the `aigenerate` function. Defaults to `:RAGAnswerRefiner`.\n\ncost_tracker: An atomic counter to track the total cost of the operations (if you want to track the cost of multiple pipeline runs - it passed around in the pipeline).\n\nReturns\n\nIf return_all is false, returns the generated message (msg).\nIf return_all is true, returns the detail of the full pipeline in RAGResult (see the docs).\n\nSee also build_index, retrieve, generate!, RAGResult, getpropertynested, setpropertynested, merge_kwargs_nested, ChunkKeywordsIndex.\n\nExamples\n\nUsing airag to get a response for a question:\n\nindex = build_index(...)  # create an index\nquestion = \"How to make a barplot in Makie.jl?\"\nmsg = airag(index; question)\n\nTo understand the details of the RAG process, use return_all=true\n\nmsg, details = airag(index; question, return_all = true)\n# details is a RAGDetails object with all the internal steps of the `airag` function\n\nYou can also pretty-print details to highlight generated text vs text that is supported by context. It also includes annotations of which context was used for each part of the response (where available).\n\nPT.pprint(details)\n\nExample with advanced retrieval (with question rephrasing and reranking (requires COHERE_API_KEY). We will obtain top 100 chunks from embeddings (top_k) and top 5 chunks from reranking (top_n). In addition, it will be done with a \"custom\" locally-hosted model.\n\ncfg = RAGConfig(; retriever = AdvancedRetriever())\n\n# kwargs will be big and nested, let's prepare them upfront\n# we specify \"custom\" model for each component that calls LLM\nkwargs = (\n\tretriever_kwargs = (;\n\t\ttop_k = 100,\n\t\ttop_n = 5,\n\t\trephraser_kwargs = (;\n\t\t\tmodel = \"custom\"),\n\t\tembedder_kwargs = (;\n\t\t\tmodel = \"custom\"),\n\t\ttagger_kwargs = (;\n\t\t\tmodel = \"custom\")),\n\tgenerator_kwargs = (;\n\t\tanswerer_kwargs = (;\n\t\t\tmodel = \"custom\"),\n\t\trefiner_kwargs = (;\n\t\t\tmodel = \"custom\")),\n\tapi_kwargs = (;\n\t\turl = \"http://localhost:8080\"))\n\nresult = airag(cfg, index, question; kwargs...)\n\nIf you want to use hybrid retrieval (embeddings + BM25), you can easily create an additional index based on keywords  and pass them both into a MultiIndex. \n\nYou need to provide an explicit config, so the pipeline knows how to handle each index in the search similarity phase (finder).\n\nindex = # your existing index\n\n# create the multi-index with the keywords index\nindex_keywords = ChunkKeywordsIndex(index)\nmulti_index = MultiIndex([index, index_keywords])\n\n# define the similarity measures for the indices that you have (same order)\nfinder = RT.MultiFinder([RT.CosineSimilarity(), RT.BM25Similarity()])\ncfg = RAGConfig(; retriever=AdvancedRetriever(; processor=RT.KeywordsProcessor(), finder))\n\n# Run the pipeline with the new hybrid retrieval (return the `RAGResult` to see the details)\nresult = airag(cfg, multi_index; question, return_all=true)\n\n# Pretty-print the result\nPT.pprint(result)\n\nFor easier manipulation of nested kwargs, see utilities getpropertynested, setpropertynested, merge_kwargs_nested.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.align_node_styles!-Tuple{TrigramAnnotater, AbstractVector{<:RAGTools.AnnotatedNode}}","page":"API Reference","title":"RAGTools.align_node_styles!","text":"align_node_styles!(annotater::TrigramAnnotater, nodes::AbstractVector{<:AnnotatedNode}; kwargs...)\n\nAligns the styles of the nodes based on the surrounding nodes (\"fill-in-the-middle\"). \n\nIf the node has no score, but the surrounding nodes have the same style, the node will inherit the style of the surrounding nodes.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.annotate_support-Tuple{TrigramAnnotater, AbstractString, AbstractVector}","page":"API Reference","title":"RAGTools.annotate_support","text":"annotate_support(annotater::TrigramAnnotater, answer::AbstractString,\n\tcontext::AbstractVector; min_score::Float64 = 0.5,\n\tskip_trigrams::Bool = true, hashed::Bool = true,\n\tsources::Union{Nothing, AbstractVector{<:AbstractString}} = nothing,\n\tmin_source_score::Float64 = 0.25,\n\tadd_sources::Bool = true,\n\tadd_scores::Bool = true, kwargs...)\n\nAnnotates the answer with the overlap/what's supported in context and returns the annotated tree of nodes representing the answer\n\nReturns a \"root\" node with children nodes representing the sentences/code blocks in the answer. Only the \"leaf\" nodes are to be printed (to avoid duplication), \"leaf\" nodes are those with NO children.\n\nDefault logic: \n\nSplit into sentences/code blocks, then into tokens (~words).\nThen match each token (~word) exactly.\nIf no exact match found, count trigram-based match (include the surrounding tokens for better contextual awareness).\nIf the match is higher than min_score, it's recorded in the score of the node.\n\nArguments\n\nannotater::TrigramAnnotater: Annotater to use\nanswer::AbstractString: Text to annotate\ncontext::AbstractVector: Context to annotate against, ie, look for \"support\" in the texts in context\nmin_score::Float64: Minimum score to consider a match. Default: 0.5, which means that half of the trigrams of each word should match\nskip_trigrams::Bool: Whether to potentially skip trigram matching if exact full match is found. Default: true\nhashed::Bool: Whether to use hashed trigrams. It's harder to debug, but it's much faster for larger texts (hashed text are held in a Set to deduplicate). Default: true\nsources::Union{Nothing, AbstractVector{<:AbstractString}}: Sources to add at the end of the context. Default: nothing\nmin_source_score::Float64: Minimum score to consider/to display a source. Default: 0.25, which means that at least a quarter of the trigrams of each word should match to some context. The threshold is lower than min_score, because it's average across ALL words in a block, so it's much harder to match fully with generated text.\nadd_sources::Bool: Whether to add sources at the end of each code block/sentence. Sources are addded in the square brackets like \"[1]\". Default: true\nadd_scores::Bool: Whether to add source-matching scores at the end of each code block/sentence. Scores are added in the square brackets like \"[0.75]\". Default: true\nkwargs: Additional keyword arguments to pass to trigram_support! and set_node_style!. See their documentation for more details (eg, customize the colors of the nodes based on the score)\n\nExample\n\nannotater = TrigramAnnotater()\ncontext = [\n\t\"This is a test context.\", \"Another context sentence.\", \"Final piece of context.\"]\nanswer = \"This is a test context. Another context sentence.\"\n\nannotated_root = annotate_support(annotater, answer, context)\npprint(annotated_root) # pretty print the annotated tree\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.annotate_support-Tuple{TrigramAnnotater, RAGTools.AbstractRAGResult}","page":"API Reference","title":"RAGTools.annotate_support","text":"annotate_support(\n\tannotater::TrigramAnnotater, result::AbstractRAGResult; min_score::Float64 = 0.5,\n\tskip_trigrams::Bool = true, hashed::Bool = true,\n\tmin_source_score::Float64 = 0.25,\n\tadd_sources::Bool = true,\n\tadd_scores::Bool = true, kwargs...)\n\nDispatch for annotate_support for AbstractRAGResult type. It extracts the final_answer and context from the result and calls annotate_support with them.\n\nSee annotate_support for more details.\n\nExample\n\nres = RAGResult(; question = \"\", final_answer = \"This is a test.\",\n\tcontext = [\"Test context.\", \"Completely different\"])\nannotated_root = annotate_support(annotater, res)\nPT.pprint(annotated_root)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.answer!-Tuple{RAGTools.SimpleAnswerer, RAGTools.AbstractDocumentIndex, RAGTools.AbstractRAGResult}","page":"API Reference","title":"RAGTools.answer!","text":"answer!(\n\tanswerer::SimpleAnswerer, index::AbstractDocumentIndex, result::AbstractRAGResult;\n\tmodel::AbstractString = PT.MODEL_CHAT, verbose::Bool = true,\n\ttemplate::Symbol = :RAGAnswerFromContext,\n\tcost_tracker = Threads.Atomic{Float64}(0.0),\n\tkwargs...)\n\nGenerates an answer using the aigenerate function with the provided result.context and result.question.\n\nReturns\n\nMutated result with result.answer and the full conversation saved in result.conversations[:answer]\n\nArguments\n\nanswerer::SimpleAnswerer: The method to use for generating the answer. Uses aigenerate.\nindex::AbstractDocumentIndex: The index containing chunks and sources.\nresult::AbstractRAGResult: The result containing the context and question to generate the answer for.\nmodel::AbstractString: The model to use for generating the answer. Defaults to PT.MODEL_CHAT.\nverbose::Bool: If true, enables verbose logging.\ntemplate::Symbol: The template to use for the aigenerate function. Defaults to :RAGAnswerFromContext.\ncost_tracker: An atomic counter to track the cost of the operation.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.bm25-Tuple{RAGTools.AbstractDocumentTermMatrix, AbstractVector{<:AbstractString}}","page":"API Reference","title":"RAGTools.bm25","text":"bm25( \tdtm::AbstractDocumentTermMatrix, query::AbstractVector{<:AbstractString}; \tk1::Float32 = 1.2f0, b::Float32 = 0.75f0, normalize::Bool = false, normalizemaxtf::Real = 3, \tnormalizemindocrellength::Float32 = 1.0f0, kwargs...)\n\nScores all documents in dtm based on the query.\n\nReferences: https://opensourceconnections.com/blog/2015/10/16/bm25-the-next-generation-of-lucene-relevation/\n\nArguments\n\ndtm: A DocumentTermMatrix object.\nquery: A vector of query tokens.\nk1: The k1 parameter for BM25.\nb: The b parameter for BM25.\nnormalize: Whether to normalize the scores (returns scores between 0 and 1). \n\nTheoretically, if you choose normalize_max_tf and normalize_min_doc_rel_length to be too low, you could get scores greater than 1.\n\nnormalize_max_tf: The maximum term frequency to normalize to. 3 is a good default (assumes max 3 hits per document).\nnormalize_min_doc_rel_length: The minimum document relative length to normalize to. 0.5 is a good default.\n\nIdeally, pick the minimum document relative length of the corpus that is non-zero min_doc_rel_length = minimum(x for x in doc_rel_length(chunkdata(key_index)) if x > 0) |> Float32\n\nExample\n\ndocuments = [[\"this\", \"is\", \"a\", \"test\"], [\"this\", \"is\", \"another\", \"test\"], [\"foo\", \"bar\", \"baz\"]]\ndtm = document_term_matrix(documents)\nquery = [\"this\"]\nscores = bm25(dtm, query)\n# Returns array with 3 scores (one for each document)\n\nNormalization is done by dividing the score by the maximum possible score (given some assumptions). It's useful to be get results in the same range as cosine similarity scores and when comparing different queries or documents.\n\ndocuments = [[\"this\", \"is\", \"a\", \"test\"], [\"this\", \"is\", \"another\", \"test\"], [\"foo\", \"bar\", \"baz\"]]\ndtm = document_term_matrix(documents)\nquery = [\"this\"]\nscores = bm25(dtm, query)\nscores_norm = bm25(dtm, query; normalize = true)\n\n## Make it more accurate for your dataset/index\nnormalize_max_tf = 3 # assume max term frequency is 3 (what is likely for your dataset? depends on chunk size, preprocessing, etc.)\nnormalize_min_doc_rel_length = minimum([x for x in doc_rel_length(dtm) if x > 0]) |> Float32\nscores_norm = bm25(dtm, query; normalize = true, normalize_max_tf, normalize_min_doc_rel_length)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.build_context-Tuple{RAGTools.ContextEnumerator, RAGTools.AbstractDocumentIndex, RAGTools.AbstractCandidateChunks}","page":"API Reference","title":"RAGTools.build_context","text":"build_context(contexter::ContextEnumerator,\n\tindex::AbstractDocumentIndex, candidates::AbstractCandidateChunks;\n\tverbose::Bool = true,\n\tchunks_window_margin::Tuple{Int, Int} = (1, 1), kwargs...)\n\n\tbuild_context!(contexter::ContextEnumerator,\n\tindex::AbstractDocumentIndex, result::AbstractRAGResult; kwargs...)\n\nBuild context strings for each position in candidates considering a window margin around each position. If mutating version is used (build_context!), it will use result.reranked_candidates to update the result.context field.\n\nArguments\n\ncontexter::ContextEnumerator: The method to use for building the context. Enumerates the snippets.\nindex::AbstractDocumentIndex: The index containing chunks and sources.\ncandidates::AbstractCandidateChunks: Candidate chunks which contain positions to extract context from.\nverbose::Bool: If true, enables verbose logging.\nchunks_window_margin::Tuple{Int, Int}: A tuple indicating the margin (before, after) around each position to include in the context.  Defaults to (1,1), which means 1 preceding and 1 suceeding chunk will be included. With (0,0), only the matching chunks will be included.\n\nReturns\n\nVector{String}: A vector of context strings, each corresponding to a position in reranked_candidates.\n\nExamples\n\nindex = ChunkIndex(...)  # Assuming a proper index is defined\ncandidates = CandidateChunks(index.id, [2, 4], [0.1, 0.2])\ncontext = build_context(ContextEnumerator(), index, candidates; chunks_window_margin=(0, 1)) # include only one following chunk for each matching chunk\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.build_index-Tuple{KeywordsIndexer, Vector{<:AbstractString}}","page":"API Reference","title":"RAGTools.build_index","text":"build_index(\n\tindexer::KeywordsIndexer, files_or_docs::Vector{<:AbstractString};\n\tverbose::Integer = 1,\n\textras::Union{Nothing, AbstractVector} = nothing,\n\tindex_id = gensym(\"ChunkKeywordsIndex\"),\n\tchunker::AbstractChunker = indexer.chunker,\n\tchunker_kwargs::NamedTuple = NamedTuple(),\n\tprocessor::AbstractProcessor = indexer.processor,\n\tprocessor_kwargs::NamedTuple = NamedTuple(),\n\ttagger::AbstractTagger = indexer.tagger,\n\ttagger_kwargs::NamedTuple = NamedTuple(),\n\tapi_kwargs::NamedTuple = NamedTuple(),\n\tcost_tracker = Threads.Atomic{Float64}(0.0))\n\nBuilds a ChunkKeywordsIndex from the provided files or documents to support keyword-based search (BM25).\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.build_index-Tuple{RAGTools.AbstractIndexBuilder, Vector{<:AbstractString}}","page":"API Reference","title":"RAGTools.build_index","text":"build_index(\n\tindexer::AbstractIndexBuilder, files_or_docs::Vector{<:AbstractString};\n\tverbose::Integer = 1,\n\textras::Union{Nothing, AbstractVector} = nothing,\n\tindex_id = gensym(\"ChunkEmbeddingsIndex\"),\n\tchunker::AbstractChunker = indexer.chunker,\n\tchunker_kwargs::NamedTuple = NamedTuple(),\n\tembedder::AbstractEmbedder = indexer.embedder,\n\tembedder_kwargs::NamedTuple = NamedTuple(),\n\ttagger::AbstractTagger = indexer.tagger,\n\ttagger_kwargs::NamedTuple = NamedTuple(),\n\tapi_kwargs::NamedTuple = NamedTuple(),\n\tcost_tracker = Threads.Atomic{Float64}(0.0))\n\nBuild an INDEX for RAG (Retriever-Augmented Generation) applications from the provided file paths.  INDEX is a object storing the document chunks and their embeddings (and potentially other information).\n\nThe function processes each file or document (depending on chunker), splits its content into chunks, embeds these chunks,  optionally extracts metadata, and then combines this information into a retrievable index.\n\nDefine your own methods via indexer and its subcomponents (chunker, embedder, tagger).\n\nArguments\n\nindexer::AbstractIndexBuilder: The indexing logic to use. Default is SimpleIndexer().\nfiles_or_docs: A vector of valid file paths OR string documents to be indexed (chunked and embedded). Specify which mode to use via chunker.\nverbose: An Integer specifying the verbosity of the logs. Default is 1 (high-level logging). 0 is disabled.\nextras: An optional vector of extra information to be stored with each chunk. Default is nothing.\nindex_id: A unique identifier for the index. Default is a generated symbol.\nchunker: The chunker logic to use for splitting the documents. Default is TextChunker().\nchunker_kwargs: Parameters to be provided to the get_chunks function. Useful to change the separators or max_length.\nsources: A vector of strings indicating the source of each chunk. Default is equal to files_or_docs.\nembedder: The embedder logic to use for embedding the chunks. Default is BatchEmbedder().\nembedder_kwargs: Parameters to be provided to the get_embeddings function. Useful to change the target_batch_size_length or reduce asyncmap tasks ntasks.\nmodel: The model to use for embedding. Default is PT.MODEL_EMBEDDING.\ntagger: The tagger logic to use for extracting tags from the chunks. Default is NoTagger(), ie, skip tag extraction. There are also PassthroughTagger and OpenTagger.\ntagger_kwargs: Parameters to be provided to the get_tags function.\nmodel: The model to use for tags extraction. Default is PT.MODEL_CHAT.\ntemplate: A template to be used for tags extraction. Default is :RAGExtractMetadataShort.\ntags: A vector of vectors of strings directly providing the tags for each chunk. Applicable for tagger::PasstroughTagger.\napi_kwargs: Parameters to be provided to the API endpoint. Shared across all API calls if provided.\ncost_tracker: A Threads.Atomic{Float64} object to track the total cost of the API calls. Useful to pass the total cost to the parent call.\n\nReturns\n\nChunkEmbeddingsIndex: An object containing the compiled index of chunks, embeddings, tags, vocabulary, and sources.\n\nSee also: ChunkEmbeddingsIndex, get_chunks, get_embeddings, get_tags, CandidateChunks, find_closest, find_tags, rerank, retrieve, generate!, airag\n\nExamples\n\n# Default is loading a vector of strings and chunking them (`TextChunker()`)\nindex = build_index(SimpleIndexer(), texts; chunker_kwargs = (; max_length=10))\n\n# Another example with tags extraction, splitting only sentences and verbose output\n# Assuming `test_files` is a vector of file paths\nindexer = SimpleIndexer(chunker=FileChunker(), tagger=OpenTagger())\nindex = build_index(indexer, test_files; \n\t\tchunker_kwargs(; separators=[\". \"]), verbose=true)\n\nNotes\n\nIf you get errors about exceeding embedding input sizes, first check the max_length in your chunks.  If that does NOT resolve the issue, try changing the embedding_kwargs.  In particular, reducing the target_batch_size_length parameter (eg, 10_000) and number of tasks ntasks=1.  Some providers cannot handle large batch sizes (eg, Databricks).\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.build_qa_evals-Tuple{Vector{<:AbstractString}, Vector{<:AbstractString}}","page":"API Reference","title":"RAGTools.build_qa_evals","text":"build_qa_evals(doc_chunks::Vector{<:AbstractString}, sources::Vector{<:AbstractString};\n\t\t\t   model=PT.MODEL_CHAT, instructions=\"None.\", qa_template::Symbol=:RAGCreateQAFromContext, \n\t\t\t   verbose::Bool=true, api_kwargs::NamedTuple = NamedTuple(), kwargs...) -> Vector{QAEvalItem}\n\nCreate a collection of question and answer evaluations (QAEvalItem) from document chunks and sources.  This function generates Q&A pairs based on the provided document chunks, using a specified AI model and template.\n\nArguments\n\ndoc_chunks::Vector{<:AbstractString}: A vector of document chunks, each representing a segment of text.\nsources::Vector{<:AbstractString}: A vector of source identifiers corresponding to each chunk in doc_chunks (eg, filenames or paths).\nmodel: The AI model used for generating Q&A pairs. Default is PT.MODEL_CHAT.\ninstructions::String: Additional instructions or context to provide to the model generating QA sets. Defaults to \"None.\".\nqa_template::Symbol: A template symbol that dictates the AITemplate that will be used. It must have placeholder context. Default is :CreateQAFromContext.\napi_kwargs::NamedTuple: Parameters that will be forwarded to the API endpoint.\nverbose::Bool: If true, additional information like costs will be logged. Defaults to true.\n\nReturns\n\nVector{QAEvalItem}: A vector of QAEvalItem structs, each containing a source, context, question, and answer. Invalid or empty items are filtered out.\n\nNotes\n\nThe function internally uses aiextract to generate Q&A pairs based on the provided qa_template. So you can use any kwargs that you want.\nEach QAEvalItem includes the context (document chunk), the generated question and answer, and the source.\nThe function tracks and reports the cost of AI calls if verbose is enabled.\nItems where the question, answer, or context is empty are considered invalid and are filtered out.\n\nExamples\n\nCreating Q&A evaluations from a set of document chunks:\n\ndoc_chunks = [\"Text from document 1\", \"Text from document 2\"]\nsources = [\"source1\", \"source2\"]\nqa_evals = build_qa_evals(doc_chunks, sources)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.build_tags","page":"API Reference","title":"RAGTools.build_tags","text":"Builds a matrix of tags and a vocabulary list. REQUIRES SparseArrays, LinearAlgebra, Unicode packages to be loaded!!\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#RAGTools.build_tags-Tuple{RAGTools.AbstractTagger, AbstractVector{<:AbstractVector{<:AbstractString}}}","page":"API Reference","title":"RAGTools.build_tags","text":"build_tags(\n\ttagger::AbstractTagger, chunk_metadata::AbstractVector{\n\t\t<:AbstractVector{<:AbstractString},\n\t})\n\nBuilds a sparse matrix of tags and a vocabulary from the given vector of chunk metadata.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.build_tags-Tuple{RAGTools.AbstractTagger, Nothing}","page":"API Reference","title":"RAGTools.build_tags","text":"build_tags(tagger::AbstractTagger, chunk_tags::Nothing; kwargs...)\n\nNo-op that skips any tag building, returning nothing, nothing\n\nOtherwise, it would build the sparse matrix and the vocabulary (requires SparseArrays and LinearAlgebra packages to be loaded).\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.chunkdata-Tuple{ChunkKeywordsIndex, AbstractVector{<:Integer}}","page":"API Reference","title":"RAGTools.chunkdata","text":"chunkdata(index::ChunkKeywordsIndex, chunk_idx::AbstractVector{<:Integer})\n\nAccess chunkdata for a subset of chunks.\n\nArguments\n\nindex::ChunkKeywordsIndex: the index to access\nchunk_idx::AbstractVector{<:Integer}: the indices of the chunks to access\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.chunkdata-Tuple{SubChunkIndex, AbstractVector{<:Integer}}","page":"API Reference","title":"RAGTools.chunkdata","text":"Access chunkdata for a subset of chunks, chunk_idx is a vector of chunk indices in the index\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.cohere_api-Tuple{}","page":"API Reference","title":"RAGTools.cohere_api","text":"cohere_api(;\napi_key::AbstractString,\nendpoint::String,\nurl::AbstractString=\"https://api.cohere.ai/v1\",\nhttp_kwargs::NamedTuple=NamedTuple(),\nkwargs...)\n\nLightweight wrapper around the Cohere API. See https://cohere.com/docs for more details.\n\nArguments\n\napi_key: Your Cohere API key. You can get one from https://dashboard.cohere.com/welcome/register (trial access is for free).\nendpoint: The Cohere endpoint to call. \nurl: The base URL for the Cohere API. Default is https://api.cohere.ai/v1.\nhttp_kwargs: Any additional keyword arguments to pass to HTTP.post.\nkwargs: Any additional keyword arguments to pass to the Cohere API.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.create_permutation_instruction-Tuple{AbstractVector{<:AbstractString}}","page":"API Reference","title":"RAGTools.create_permutation_instruction","text":"create_permutation_instruction(\n\tcontext::AbstractVector{<:AbstractString}; rank_start::Integer = 1,\n\trank_end::Integer = 100, max_length::Integer = 512, template::Symbol = :RAGRankGPT)\n\nCreates rendered template with injected context passages.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.create_websearch-Tuple{AbstractString}","page":"API Reference","title":"RAGTools.create_websearch","text":"create_websearch(query::AbstractString;\n\tapi_key::AbstractString,\n\tsearch_depth::AbstractString = \"basic\")\n\nArguments\n\nquery::AbstractString: The query to search for.\napi_key::AbstractString: The API key to use for the search. Get an API key from Tavily.\nsearch_depth::AbstractString: The depth of the search. Can be either \"basic\" or \"advanced\". Default is \"basic\". Advanced search calls equal to 2 requests.\ninclude_answer::Bool: Whether to include the answer in the search results. Default is false.\ninclude_raw_content::Bool: Whether to include the raw content in the search results. Default is false.\nmax_results::Integer: The maximum number of results to return. Default is 5.\ninclude_images::Bool: Whether to include images in the search results. Default is false.\ninclude_domains::AbstractVector{<:AbstractString}: A list of domains to include in the search results. Default is an empty list.\nexclude_domains::AbstractVector{<:AbstractString}: A list of domains to exclude from the search results. Default is an empty list.\n\nExample\n\nr = create_websearch(\"Who is King Charles?\")\n\nEven better, you can get not just the results but also the answer:\n\nr = create_websearch(\"Who is King Charles?\"; include_answer = true)\n\nSee Rest API documentation for more information.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.doc_rel_length-Tuple{RAGTools.AbstractDocumentTermMatrix}","page":"API Reference","title":"RAGTools.doc_rel_length","text":"doc_rel_length(dtm::AbstractDocumentTermMatrix)\n\nGet the document relative length vector of an AbstractDocumentTermMatrix.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.document_term_matrix-Union{Tuple{AbstractVector{<:AbstractVector{T}}}, Tuple{T}} where T<:AbstractString","page":"API Reference","title":"RAGTools.document_term_matrix","text":"documenttermmatrix( \tdocuments::AbstractVector{<:AbstractVector{T}}; \tmintermfreq::Int = 1, max_terms::Int = typemax(Int)) where {T <: AbstractString}\n\nBuilds a sparse matrix of term frequencies and document lengths from the given vector of documents wrapped in type DocumentTermMatrix.\n\nExpects a vector of preprocessed (tokenized) documents, where each document is a vector of strings (clean tokens).\n\nReturns: DocumentTermMatrix\n\nArguments\n\ndocuments: A vector of documents, where each document is a vector of terms (clean tokens).\nmin_term_freq: The minimum frequency a term must have to be included in the vocabulary, eg, min_term_freq = 2 means only terms that appear at least twice will be included.\nmax_terms: The maximum number of terms to include in the vocabulary, eg, max_terms = 100 means only the 100 most frequent terms will be included.\n\nExample\n\ndocuments = [[\"this\", \"is\", \"a\", \"test\"], [\"this\", \"is\", \"another\", \"test\"], [\"foo\", \"bar\", \"baz\"]]\ndtm = document_term_matrix(documents)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.extract_ranking-Tuple{AbstractString}","page":"API Reference","title":"RAGTools.extract_ranking","text":"extract_ranking(str::AbstractString)\n\nExtracts the ranking from the response into a sorted array of integers.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.find_closest","page":"API Reference","title":"RAGTools.find_closest","text":"find_closest(\n\tfinder::AbstractSimilarityFinder, index::AbstractChunkIndex,\n\tquery_emb::AbstractVector{<:Real}, query_tokens::AbstractVector{<:AbstractString} = String[];\n\ttop_k::Int = 100, kwargs...)\n\nFinds the indices of chunks (represented by embeddings in index) that are closest to query embedding (query_emb).\n\nReturns only top_k closest indices.\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#RAGTools.find_closest-2","page":"API Reference","title":"RAGTools.find_closest","text":"find_closest(\n\tfinder::BinaryCosineSimilarity, emb::AbstractMatrix{<:Bool},\n\tquery_emb::AbstractVector{<:Real}, query_tokens::AbstractVector{<:AbstractString} = String[];\n\ttop_k::Int = 100, rescore_multiplier::Int = 4, minimum_similarity::AbstractFloat = -1.0, kwargs...)\n\nFinds the indices of chunks (represented by embeddings in emb) that are closest to query embedding (query_emb) using binary embeddings (in the index).\n\nThis is a two-pass approach:\n\nFirst pass: Hamming distance in binary form to get the top_k * rescore_multiplier (ie, more than top_k) candidates.\nSecond pass: Rescore the candidates with float embeddings and return the top_k.\n\nReturns only top_k closest indices.\n\nReference: HuggingFace: Embedding Quantization.\n\nExamples\n\nConvert any Float embeddings to binary like this:\n\nbinary_emb = map(>(0), emb)\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#RAGTools.find_closest-3","page":"API Reference","title":"RAGTools.find_closest","text":"find_closest(\n\tfinder::CosineSimilarity, emb::AbstractMatrix{<:Real},\n\tquery_emb::AbstractVector{<:Real}, query_tokens::AbstractVector{<:AbstractString} = String[];\n\ttop_k::Int = 100, minimum_similarity::AbstractFloat = -1.0, kwargs...)\n\nFinds the indices of chunks (represented by embeddings in emb) that are closest (in cosine similarity for CosineSimilarity()) to query embedding (query_emb). \n\nfinder is the logic used for the similarity search. Default is CosineSimilarity.\n\nIf minimum_similarity is provided, only indices with similarity greater than or equal to it are returned.  Similarity can be between -1 and 1 (-1 = completely opposite, 1 = exactly the same).\n\nReturns only top_k closest indices.\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#RAGTools.find_closest-4","page":"API Reference","title":"RAGTools.find_closest","text":"find_closest(\n\tfinder::BitPackedCosineSimilarity, emb::AbstractMatrix{<:Bool},\n\tquery_emb::AbstractVector{<:Real}, query_tokens::AbstractVector{<:AbstractString} = String[];\n\ttop_k::Int = 100, rescore_multiplier::Int = 4, minimum_similarity::AbstractFloat = -1.0, kwargs...)\n\nFinds the indices of chunks (represented by embeddings in emb) that are closest to query embedding (query_emb) using bit-packed binary embeddings (in the index).\n\nThis is a two-pass approach:\n\nFirst pass: Hamming distance in bit-packed binary form to get the top_k * rescore_multiplier (i.e., more than top_k) candidates.\nSecond pass: Rescore the candidates with float embeddings and return the top_k.\n\nReturns only top_k closest indices.\n\nReference: HuggingFace: Embedding Quantization.\n\nExamples\n\nConvert any Float embeddings to bit-packed binary like this:\n\nbitpacked_emb = pack_bits(emb.>0)\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#RAGTools.find_closest-5","page":"API Reference","title":"RAGTools.find_closest","text":"find_closest(\n\tfinder::BM25Similarity, dtm::AbstractDocumentTermMatrix,\n\tquery_emb::AbstractVector{<:Real}, query_tokens::AbstractVector{<:AbstractString} = String[];\n\ttop_k::Int = 100, minimum_similarity::AbstractFloat = -1.0, kwargs...)\n\nFinds the indices of chunks (represented by DocumentTermMatrix in dtm) that are closest to query tokens (query_tokens) using BM25.\n\nReference: Wikipedia: BM25. Implementation follows: The Next Generation of Lucene Relevance.\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#RAGTools.find_tags-Tuple{RAGTools.AnyTagFilter, RAGTools.AbstractChunkIndex, Union{Regex, AbstractString}}","page":"API Reference","title":"RAGTools.find_tags","text":"find_tags(method::AnyTagFilter, index::AbstractChunkIndex,\n\ttag::Union{AbstractString, Regex}; kwargs...)\n\nfind_tags(method::AnyTagFilter, index::AbstractChunkIndex,\n\ttags::Vector{T}; kwargs...) where {T <: Union{AbstractString, Regex}}\n\nFinds the indices of chunks (represented by tags in index) that have ANY OF the specified tag or tags.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.find_tags-Union{Tuple{T}, Tuple{RAGTools.AllTagFilter, RAGTools.AbstractChunkIndex, Vector{T}}} where T<:Union{Regex, AbstractString}","page":"API Reference","title":"RAGTools.find_tags","text":"find_tags(method::AllTagFilter, index::AbstractChunkIndex,\n\ttag::Union{AbstractString, Regex}; kwargs...)\n\nfind_tags(method::AllTagFilter, index::AbstractChunkIndex,\n\ttags::Vector{T}; kwargs...) where {T <: Union{AbstractString, Regex}}\n\nFinds the indices of chunks (represented by tags in index) that have ALL OF the specified tag or tags.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.find_tags-Union{Tuple{T}, Tuple{RAGTools.NoTagFilter, RAGTools.AbstractChunkIndex, Union{AbstractVector{<:T}, T}}} where T<:Union{Nothing, Regex, AbstractString}","page":"API Reference","title":"RAGTools.find_tags","text":"find_tags(method::NoTagFilter, index::AbstractChunkIndex,\n\ttags::Union{T, AbstractVector{<:T}}; kwargs...) where {T <:\n\t\t\t\t\t\t\t\t\t\t\t\t\t\t   Union{\n\tAbstractString, Regex, Nothing}}\n\ttags; kwargs...)\n\nReturns all chunks in the index, ie, no filtering, so we simply return nothing (easier for dispatch).\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.generate!-Tuple{RAGTools.AbstractGenerator, RAGTools.AbstractDocumentIndex, RAGTools.AbstractRAGResult}","page":"API Reference","title":"RAGTools.generate!","text":"generate!(\n\tgenerator::AbstractGenerator, index::AbstractDocumentIndex, result::AbstractRAGResult;\n\tverbose::Integer = 1,\n\tapi_kwargs::NamedTuple = NamedTuple(),\n\tcontexter::AbstractContextBuilder = generator.contexter,\n\tcontexter_kwargs::NamedTuple = NamedTuple(),\n\tanswerer::AbstractAnswerer = generator.answerer,\n\tanswerer_kwargs::NamedTuple = NamedTuple(),\n\trefiner::AbstractRefiner = generator.refiner,\n\trefiner_kwargs::NamedTuple = NamedTuple(),\n\tpostprocessor::AbstractPostprocessor = generator.postprocessor,\n\tpostprocessor_kwargs::NamedTuple = NamedTuple(),\n\tcost_tracker = Threads.Atomic{Float64}(0.0),\n\tkwargs...)\n\nGenerate the response using the provided generator and the index and result. It is the second step in the RAG pipeline (after retrieve)\n\nReturns the mutated result with the result.final_answer and the full conversation saved in result.conversations[:final_answer].\n\nNotes\n\nThe default flow is build_context! -> answer! -> refine! -> postprocess!.\ncontexter is the method to use for building the context, eg, simply enumerate the context chunks with ContextEnumerator.\nanswerer is the standard answer generation step with LLMs.\nrefiner step allows the LLM to critique itself and refine its own answer.\npostprocessor step allows for additional processing of the answer, eg, logging, saving conversations, etc.\nAll of its sub-routines operate by mutating the result object (and adding their part).\nDiscover available sub-types for each step with subtypes(AbstractRefiner) and similar for other abstract types.\n\nArguments\n\ngenerator::AbstractGenerator: The generator to use for generating the answer. Can be SimpleGenerator or AdvancedGenerator.\nindex::AbstractDocumentIndex: The index containing chunks and sources.\nresult::AbstractRAGResult: The result containing the context and question to generate the answer for.\nverbose::Integer: If >0, enables verbose logging.\napi_kwargs::NamedTuple: API parameters that will be forwarded to ALL of the API calls (aiembed, aigenerate, and aiextract).\ncontexter::AbstractContextBuilder: The method to use for building the context. Defaults to generator.contexter, eg, ContextEnumerator.\ncontexter_kwargs::NamedTuple: API parameters that will be forwarded to the contexter call.\nanswerer::AbstractAnswerer: The method to use for generating the answer. Defaults to generator.answerer, eg, SimpleAnswerer.\nanswerer_kwargs::NamedTuple: API parameters that will be forwarded to the answerer call. Examples:\n\n- `model`: The model to use for generating the answer. Defaults to `PT.MODEL_CHAT`.\n- `template`: The template to use for the `aigenerate` function. Defaults to `:RAGAnswerFromContext`.\n\nrefiner::AbstractRefiner: The method to use for refining the answer. Defaults to generator.refiner, eg, NoRefiner.\nrefiner_kwargs::NamedTuple: API parameters that will be forwarded to the refiner call.\n\n- `model`: The model to use for generating the answer. Defaults to `PT.MODEL_CHAT`.\n- `template`: The template to use for the `aigenerate` function. Defaults to `:RAGAnswerRefiner`.\n\npostprocessor::AbstractPostprocessor: The method to use for postprocessing the answer. Defaults to generator.postprocessor, eg, NoPostprocessor.\npostprocessor_kwargs::NamedTuple: API parameters that will be forwarded to the postprocessor call.\ncost_tracker: An atomic counter to track the total cost of the operations.\n\nSee also: retrieve, build_context!, ContextEnumerator, answer!, SimpleAnswerer, refine!, NoRefiner, SimpleRefiner, postprocess!, NoPostprocessor\n\nExamples\n\nAssume we already have `index`\n\nquestion = \"What are the best practices for parallel computing in Julia?\"\n\n# Retrieve the relevant chunks - returns RAGResult\nresult = retrieve(index, question)\n\n# Generate the answer using the default generator, mutates the same result\nresult = generate!(index, result)\n\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.get_chunks-Tuple{RAGTools.AbstractChunker, Vector{<:AbstractString}}","page":"API Reference","title":"RAGTools.get_chunks","text":"get_chunks(chunker::AbstractChunker,\n\tfiles_or_docs::Vector{<:AbstractString};\n\tsources::AbstractVector{<:AbstractString} = files_or_docs,\n\tverbose::Bool = true,\n\tseparators = [\"\\n\\n\", \". \", \"\\n\", \" \"], max_length::Int = 256)\n\nChunks the provided files_or_docs into chunks of maximum length max_length (if possible with provided separators).\n\nSupports two modes of operation:\n\nchunker = FileChunker(): The function opens each file in files_or_docs and reads its contents.\nchunker = TextChunker(): The function assumes that files_or_docs is a vector of strings to be chunked, you MUST provide corresponding sources.\n\nArguments\n\nfiles_or_docs: A vector of valid file paths OR string documents to be chunked.\nseparators: A list of strings used as separators for splitting the text in each file into chunks. Default is [\\n\\n\", \". \", \"\\n\", \" \"].  See recursive_splitter for more details.\nmax_length: The maximum length of each chunk (if possible with provided separators). Default is 256.\nsources: A vector of strings indicating the source of each chunk. Default is equal to files_or_docs (for reader=:files)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.get_embeddings-Tuple{RAGTools.BatchEmbedder, AbstractVector{<:AbstractString}}","page":"API Reference","title":"RAGTools.get_embeddings","text":"get_embeddings(embedder::BatchEmbedder, docs::AbstractVector{<:AbstractString};\n\tverbose::Bool = true,\n\tmodel::AbstractString = PT.MODEL_EMBEDDING,\n\ttruncate_dimension::Union{Int, Nothing} = nothing,\n\tcost_tracker = Threads.Atomic{Float64}(0.0),\n\ttarget_batch_size_length::Int = 80_000,\n\tntasks::Int = 4 * Threads.nthreads(),\n\tkwargs...)\n\nEmbeds a vector of docs using the provided model (kwarg model) in a batched manner - BatchEmbedder.\n\nBatchEmbedder tries to batch embedding calls for roughly 80K characters per call (to avoid exceeding the API rate limit) to reduce network latency.\n\nNotes\n\ndocs are assumed to be already chunked to the reasonable sizes that fit within the embedding context limit.\nIf you get errors about exceeding input sizes, first check the max_length in your chunks.  If that does NOT resolve the issue, try reducing the target_batch_size_length parameter (eg, 10_000) and number of tasks ntasks=1.  Some providers cannot handle large batch sizes.\n\nArguments\n\ndocs: A vector of strings to be embedded.\nverbose: A boolean flag for verbose output. Default is true.\nmodel: The model to use for embedding. Default is PT.MODEL_EMBEDDING.\ntruncate_dimension: The dimensionality of the embeddings to truncate to. Default is nothing, 0 will also do nothing.\ncost_tracker: A Threads.Atomic{Float64} object to track the total cost of the API calls. Useful to pass the total cost to the parent call.\ntarget_batch_size_length: The target length (in characters) of each batch of document chunks sent for embedding. Default is 80_000 characters. Speeds up embedding process.\nntasks: The number of tasks to use for asyncmap. Default is 4 * Threads.nthreads().\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.get_embeddings-Tuple{RAGTools.BinaryBatchEmbedder, AbstractVector{<:AbstractString}}","page":"API Reference","title":"RAGTools.get_embeddings","text":"get_embeddings(embedder::BinaryBatchEmbedder, docs::AbstractVector{<:AbstractString};\n\tverbose::Bool = true,\n\tmodel::AbstractString = PT.MODEL_EMBEDDING,\n\ttruncate_dimension::Union{Int, Nothing} = nothing,\n\treturn_type::Type = Matrix{Bool},\n\tcost_tracker = Threads.Atomic{Float64}(0.0),\n\ttarget_batch_size_length::Int = 80_000,\n\tntasks::Int = 4 * Threads.nthreads(),\n\tkwargs...)\n\nEmbeds a vector of docs using the provided model (kwarg model) in a batched manner and then returns the binary embeddings matrix - BinaryBatchEmbedder.\n\nBinaryBatchEmbedder tries to batch embedding calls for roughly 80K characters per call (to avoid exceeding the API rate limit) to reduce network latency.\n\nNotes\n\ndocs are assumed to be already chunked to the reasonable sizes that fit within the embedding context limit.\nIf you get errors about exceeding input sizes, first check the max_length in your chunks.  If that does NOT resolve the issue, try reducing the target_batch_size_length parameter (eg, 10_000) and number of tasks ntasks=1.  Some providers cannot handle large batch sizes.\n\nArguments\n\ndocs: A vector of strings to be embedded.\nverbose: A boolean flag for verbose output. Default is true.\nmodel: The model to use for embedding. Default is PT.MODEL_EMBEDDING.\ntruncate_dimension: The dimensionality of the embeddings to truncate to. Default is nothing.\nreturn_type: The type of the returned embeddings matrix. Default is Matrix{Bool}. Choose BitMatrix to minimize storage requirements, Matrix{Bool} to maximize performance in elementwise-ops.\ncost_tracker: A Threads.Atomic{Float64} object to track the total cost of the API calls. Useful to pass the total cost to the parent call.\ntarget_batch_size_length: The target length (in characters) of each batch of document chunks sent for embedding. Default is 80_000 characters. Speeds up embedding process.\nntasks: The number of tasks to use for asyncmap. Default is 4 * Threads.nthreads().\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.get_embeddings-Tuple{RAGTools.BitPackedBatchEmbedder, AbstractVector{<:AbstractString}}","page":"API Reference","title":"RAGTools.get_embeddings","text":"get_embeddings(embedder::BitPackedBatchEmbedder, docs::AbstractVector{<:AbstractString};\n\tverbose::Bool = true,\n\tmodel::AbstractString = PT.MODEL_EMBEDDING,\n\ttruncate_dimension::Union{Int, Nothing} = nothing,\n\tcost_tracker = Threads.Atomic{Float64}(0.0),\n\ttarget_batch_size_length::Int = 80_000,\n\tntasks::Int = 4 * Threads.nthreads(),\n\tkwargs...)\n\nEmbeds a vector of docs using the provided model (kwarg model) in a batched manner and then returns the binary embeddings matrix represented in UInt64 (bit-packed) - BitPackedBatchEmbedder.\n\nBitPackedBatchEmbedder tries to batch embedding calls for roughly 80K characters per call (to avoid exceeding the API rate limit) to reduce network latency.\n\nThe best option for FAST and MEMORY-EFFICIENT storage of embeddings, for retrieval use BitPackedCosineSimilarity.\n\nNotes\n\ndocs are assumed to be already chunked to the reasonable sizes that fit within the embedding context limit.\nIf you get errors about exceeding input sizes, first check the max_length in your chunks.  If that does NOT resolve the issue, try reducing the target_batch_size_length parameter (eg, 10_000) and number of tasks ntasks=1.  Some providers cannot handle large batch sizes.\n\nArguments\n\ndocs: A vector of strings to be embedded.\nverbose: A boolean flag for verbose output. Default is true.\nmodel: The model to use for embedding. Default is PT.MODEL_EMBEDDING.\ntruncate_dimension: The dimensionality of the embeddings to truncate to. Default is nothing.\ncost_tracker: A Threads.Atomic{Float64} object to track the total cost of the API calls. Useful to pass the total cost to the parent call.\ntarget_batch_size_length: The target length (in characters) of each batch of document chunks sent for embedding. Default is 80_000 characters. Speeds up embedding process.\nntasks: The number of tasks to use for asyncmap. Default is 4 * Threads.nthreads().\n\nSee also: unpack_bits, pack_bits, BitPackedCosineSimilarity.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.get_keywords-Tuple{RAGTools.KeywordsProcessor, AbstractVector{<:AbstractString}}","page":"API Reference","title":"RAGTools.get_keywords","text":"get_keywords(\n\tprocessor::KeywordsProcessor, docs::AbstractVector{<:AbstractString};\n\tverbose::Bool = true,\n\tstemmer = nothing,\n\tstopwords::Set{String} = Set(STOPWORDS),\n\treturn_keywords::Bool = false,\n\tmin_length::Integer = 3,\n\tmin_term_freq::Int = 1, max_terms::Int = typemax(Int),\n\tkwargs...)\n\nGenerate a DocumentTermMatrix from a vector of docs using the provided stemmer and stopwords.\n\nArguments\n\ndocs: A vector of strings to be embedded.\nverbose: A boolean flag for verbose output. Default is true.\nstemmer: A stemmer to use for stemming. Default is nothing.\nstopwords: A set of stopwords to remove. Default is Set(STOPWORDS).\nreturn_keywords: A boolean flag for returning the keywords. Default is false. Useful for query processing in search time.\nmin_length: The minimum length of the keywords. Default is 3.\nmin_term_freq: The minimum frequency a term must have to be included in the vocabulary, eg, min_term_freq = 2 means only terms that appear at least twice will be included.\nmax_terms: The maximum number of terms to include in the vocabulary, eg, max_terms = 100 means only the 100 most frequent terms will be included.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.get_tags-Tuple{RAGTools.NoTagger, AbstractVector{<:AbstractString}}","page":"API Reference","title":"RAGTools.get_tags","text":"get_tags(tagger::NoTagger, docs::AbstractVector{<:AbstractString};\n\tkwargs...)\n\nSimple no-op that skips any tagging of the documents\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.get_tags-Tuple{RAGTools.OpenTagger, AbstractVector{<:AbstractString}}","page":"API Reference","title":"RAGTools.get_tags","text":"get_tags(tagger::OpenTagger, docs::AbstractVector{<:AbstractString};\n\tverbose::Bool = true,\n\tcost_tracker = Threads.Atomic{Float64}(0.0),\n\tkwargs...)\n\nExtracts \"tags\" (metadata/keywords) from a vector of docs using the provided model (kwarg model).\n\nArguments\n\ndocs: A vector of strings to be embedded.\nverbose: A boolean flag for verbose output. Default is true.\nmodel: The model to use for tags extraction. Default is PT.MODEL_CHAT.\ntemplate: A template to be used for tags extraction. Default is :RAGExtractMetadataShort.\ncost_tracker: A Threads.Atomic{Float64} object to track the total cost of the API calls. Useful to pass the total cost to the parent call.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.get_tags-Tuple{RAGTools.PassthroughTagger, AbstractVector{<:AbstractString}}","page":"API Reference","title":"RAGTools.get_tags","text":"get_tags(tagger::PassthroughTagger, docs::AbstractVector{<:AbstractString};\n\ttags::AbstractVector{<:AbstractVector{<:AbstractString}},\n\tkwargs...)\n\nPass tags directly as Vector of Vectors of strings (ie, tags[i] is the tags for docs[i]). It then builds the vocabulary from the tags and returns both the tags in matrix form and the vocabulary.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.getpropertynested","page":"API Reference","title":"RAGTools.getpropertynested","text":"getpropertynested(\n\tnt::NamedTuple, parent_keys::Vector{Symbol}, key::Symbol, default = nothing)\n\nGet a property key from a nested NamedTuple nt, where the property is nested to a key in parent_keys.\n\nUseful for nested kwargs where we want to get some property in parent_keys subset (eg, model in retriever_kwargs).\n\nExamples\n\nkw = (; abc = (; def = \"x\"))\ngetpropertynested(kw, [:abc], :def)\n# Output: \"x\"\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#RAGTools.hamming_distance-Union{Tuple{T}, Tuple{AbstractMatrix{T}, AbstractVector{T}}} where T<:Integer","page":"API Reference","title":"RAGTools.hamming_distance","text":"hamming_distance(\n\tmat::AbstractMatrix{T}, query::AbstractVector{T})::Vector{Int} where {T <: Integer}\n\nCalculates the column-wise Hamming distance between a matrix of binary vectors mat and a single binary vector vect.\n\nThis is the first-pass ranking for BinaryCosineSimilarity method.\n\nImplementation from domluna's tinyRAG.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.hcat_truncate-Union{Tuple{AbstractVector{<:AbstractMatrix{T}}}, Tuple{T}, Tuple{AbstractVector{<:AbstractMatrix{T}}, Union{Nothing, Int64}}} where T<:Real","page":"API Reference","title":"RAGTools.hcat_truncate","text":"hcat_truncate(\n\tmatrices::AbstractVector{<:AbstractMatrix{T}},\n\ttruncate_dimension::Union{Nothing, Int} = nothing;\n\tverbose::Bool = false,\n) where {T <: Real}\n\nHorizontal concatenation of matrices, with optional truncation of the rows of each matrix to the specified dimension (reducing embedding dimensionality).\n\nMore efficient that a simple splatting, as the resulting matrix is pre-allocated in one go.\n\nReturns: a Matrix{Float32}\n\nArguments\n\nmatrices::AbstractVector{<:AbstractMatrix{T}}: Vector of matrices to concatenate\ntruncate_dimension::Union{Nothing,Int}=nothing: Dimension to truncate to, or nothing or 0 to skip truncation. If truncated, the columns will be normalized.\nverbose::Bool=false: Whether to print verbose output.\n\nExamples\n\na = rand(Float32, 1000, 10)\nb = rand(Float32, 1000, 20)\n\nc = hcat_truncate([a, b])\nsize(c) # (1000, 30)\n\nd = hcat_truncate([a, b], 500)\nsize(d) # (500, 30)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.idf-Tuple{RAGTools.AbstractDocumentTermMatrix}","page":"API Reference","title":"RAGTools.idf","text":"idf(dtm::AbstractDocumentTermMatrix)\n\nGet the inverse document frequency vector of an AbstractDocumentTermMatrix.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.load_text-Tuple{RAGTools.AbstractChunker, Any}","page":"API Reference","title":"RAGTools.load_text","text":"load_text(chunker::AbstractChunker, input;\n\tkwargs...)\n\nLoad text from input using the provided chunker. Called by get_chunks.\n\nAvailable chunkers:\n\nFileChunker: The function opens each file in input and reads its contents.\nTextChunker: The function assumes that input is a vector of strings to be chunked, you MUST provide corresponding sources.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.max_bm25_score-Tuple{RAGTools.AbstractDocumentTermMatrix, AbstractVector{<:AbstractString}}","page":"API Reference","title":"RAGTools.max_bm25_score","text":"maxbm25score( \tdtm::AbstractDocumentTermMatrix, querytokens::AbstractVector{<:AbstractString}; \tk1::Float32 = 1.2f0, b::Float32 = 0.75f0, maxtf::Real = 3, \tmindocrel_length::Float32 = 0.5f0)\n\nReturns the maximum BM25 score that can be achieved for a given query (assuming the max_tf matches and the min_doc_rel_length being the smallest document relative length). Good for normalizing BM25 scores.\n\nExample\n\nmax_score = max_bm25_score(chunkdata(key_index), query_tokens)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.merge_kwargs_nested-Tuple{NamedTuple, NamedTuple}","page":"API Reference","title":"RAGTools.merge_kwargs_nested","text":"merge_kwargs_nested(nt1::NamedTuple, nt2::NamedTuple)\n\nMerges two nested NamedTuples nt1 and nt2 recursively. The nt2 values will overwrite the nt1 values when overlapping.\n\nExample\n\nkw = (; abc = (; def = \"x\"))\nkw2 = (; abc = (; def = \"x\", def2 = 2), new = 1)\nmerge_kwargs_nested(kw, kw2)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.pack_bits-Tuple{AbstractMatrix{<:Bool}}","page":"API Reference","title":"RAGTools.pack_bits","text":"pack_bits(arr::AbstractMatrix{<:Bool}) -> Matrix{UInt64}\npack_bits(vect::AbstractVector{<:Bool}) -> Vector{UInt64}\n\nPack a matrix or vector of boolean values into a more compact representation using UInt64.\n\nArguments (Input)\n\narr::AbstractMatrix{<:Bool}: A matrix of boolean values where the number of rows must be divisible by 64.\n\nReturns\n\nFor arr::AbstractMatrix{<:Bool}: Returns a matrix of UInt64 where each element represents 64 boolean values from the original matrix.\n\nExamples\n\nFor vectors:\n\nbin = rand(Bool, 128)\nbinint = pack_bits(bin)\nbinx = unpack_bits(binint)\n@assert bin == binx\n\nFor matrices:\n\nbin = rand(Bool, 128, 10)\nbinint = pack_bits(bin)\nbinx = unpack_bits(binint)\n@assert bin == binx\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.permutation_step!-Tuple{RAGTools.RankGPTResult}","page":"API Reference","title":"RAGTools.permutation_step!","text":"permutation_step!(\n\tresult::RankGPTResult; rank_start::Integer = 1, rank_end::Integer = 100, kwargs...)\n\nOne sub-step of the RankGPT algorithm permutation ranking within the window of chunks defined by rank_start and rank_end positions.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.preprocess_tokens","page":"API Reference","title":"RAGTools.preprocess_tokens","text":"preprocess_tokens(text::AbstractString, stemmer=nothing; stopwords::Union{Nothing,Set{String}}=nothing, min_length::Int=3)\n\nPreprocess provided text by removing numbers, punctuation, and applying stemming for BM25 search index.\n\nReturns a list of preprocessed tokens.\n\nExample\n\nstemmer = Snowball.Stemmer(\"english\")\nstopwords = Set([\"a\", \"an\", \"and\", \"are\", \"as\", \"at\", \"be\", \"but\", \"by\", \"for\", \"if\", \"in\", \"into\", \"is\", \"it\", \"no\", \"not\", \"of\", \"on\", \"or\", \"such\", \"some\", \"that\", \"the\", \"their\", \"then\", \"there\", \"these\", \"they\", \"this\", \"to\", \"was\", \"will\", \"with\"])\ntext = \"This is a sample paragraph to test the functionality of your text preprocessor. It contains a mix of uppercase and lowercase letters, as well as punctuation marks such as commas, periods, and exclamation points! Let's see how your preprocessor handles quotes, like \"this one\", and also apostrophes, like in don't. Will it preserve the formatting of this paragraph, including the indentation and line breaks?\"\npreprocess_tokens(text, stemmer; stopwords)\n\n\n\n\n\n","category":"function"},{"location":"api_reference/#RAGTools.print_html-Tuple{IO, RAGTools.AbstractAnnotatedNode}","page":"API Reference","title":"RAGTools.print_html","text":"print_html([io::IO,] parent_node::AbstractAnnotatedNode)\n\nprint_html([io::IO,] rag::AbstractRAGResult; add_sources::Bool = false,\n\tadd_scores::Bool = false, default_styler = HTMLStyler(),\n\tlow_styler = HTMLStyler(styles = \"color:magenta\", classes = \"\"),\n\tmedium_styler = HTMLStyler(styles = \"color:blue\", classes = \"\"),\n\thigh_styler = HTMLStyler(styles = \"\", classes = \"\"), styler_kwargs...)\n\nPretty-prints the annotation parent_node (or RAGResult) to the io stream (or returns the string) in HTML format (assumes node is styled with styler HTMLStyler).\n\nIt wraps each \"token\" into a span with requested styling (HTMLStyler's properties classes and styles). It also replaces new lines with <br> for better HTML formatting.\n\nFor any non-HTML styler, it prints the content as plain text.\n\nReturns\n\nnothing if io is provided\nor the string with HTML-formatted text (if io is not provided, we print the result out)\n\nSee also HTMLStyler, annotate_support, and set_node_style! for how the styling is applied and what the arguments mean.\n\nExamples\n\nNote: RT is an alias for RAGTools\n\nSimple start directly with the RAGResult:\n\n# set up the text/RAGResult\ncontext = [\n\t\"This is a test context.\", \"Another context sentence.\", \"Final piece of context.\"]\nanswer = \"This is a test answer. It has multiple sentences.\"\nrag = RT.RAGResult(; context, final_answer=answer, question=\"\")\n\n# print the HTML\nprint_html(rag)\n\nLow-level control by creating our AnnotatedNode:\n\n# prepare your HTML styling\nstyler_kwargs = (;\n\tdefault_styler=RT.HTMLStyler(),\n\tlow_styler=RT.HTMLStyler(styles=\"color:magenta\", classes=\"\"),\n\tmedium_styler=RT.HTMLStyler(styles=\"color:blue\", classes=\"\"),\n\thigh_styler=RT.HTMLStyler(styles=\"\", classes=\"\"))\n\n# annotate the text\ncontext = [\n\t\"This is a test context.\", \"Another context sentence.\", \"Final piece of context.\"]\nanswer = \"This is a test answer. It has multiple sentences.\"\n\nparent_node = RT.annotate_support(\n\tRT.TrigramAnnotater(), answer, context; add_sources=false, add_scores=false, styler_kwargs...)\n\n# print the HTML\nprint_html(parent_node)\n\n# or to accumulate more nodes\nio = IOBuffer()\nprint_html(io, parent_node)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.rank_gpt-Tuple{AbstractVector{<:AbstractString}, AbstractString}","page":"API Reference","title":"RAGTools.rank_gpt","text":"rank_gpt(chunks::AbstractVector{<:AbstractString}, question::AbstractString;\n\tverbose::Int = 1, rank_start::Integer = 1, rank_end::Integer = 100,\n\twindow_size::Integer = 20, step::Integer = 10,\n\tnum_rounds::Integer = 1, model::String = \"gpt4o\", kwargs...)\n\nRanks the chunks based on their relevance for question. Returns the ranking permutation of the chunks in the order they are most relevant to the question (the first is the most relevant).\n\nExample\n\nresult = rank_gpt(chunks, question; rank_start=1, rank_end=25, window_size=8, step=4, num_rounds=3, model=\"gpt4o\")\n\nReference\n\n[1] Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents by W. Sun et al. [2] RankGPT Github\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.rank_sliding_window!-Tuple{RAGTools.RankGPTResult}","page":"API Reference","title":"RAGTools.rank_sliding_window!","text":"rank_sliding_window!(\n\tresult::RankGPTResult; verbose::Int = 1, rank_start = 1, rank_end = 100,\n\twindow_size = 20, step = 10, model::String = \"gpt4o\", kwargs...)\n\nOne single pass of the RankGPT algorithm permutation ranking across all positions between rank_start and rank_end.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.receive_permutation!-Tuple{AbstractVector{<:Integer}, AbstractString}","page":"API Reference","title":"RAGTools.receive_permutation!","text":"receive_permutation!(\n\tcurr_rank::AbstractVector{<:Integer}, response::AbstractString;\n\trank_start::Integer = 1, rank_end::Integer = 100)\n\nExtracts and heals the permutation to contain all ranking positions.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.reciprocal_rank_fusion-Tuple","page":"API Reference","title":"RAGTools.reciprocal_rank_fusion","text":"reciprocal_rank_fusion(args...; k::Int=60)\n\nMerges multiple rankings and calculates the reciprocal rank score for each chunk (discounted by the inverse of the rank).\n\nExample\n\npositions1 = [1, 3, 5, 7, 9]\npositions2 = [2, 4, 6, 8, 10]\npositions3 = [2, 4, 6, 11, 12]\n\nmerged_positions, scores = reciprocal_rank_fusion(positions1, positions2, positions3)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.reciprocal_rank_fusion-Tuple{MultiCandidateChunks}","page":"API Reference","title":"RAGTools.reciprocal_rank_fusion","text":"reciprocal_rank_fusion(mcc::MultiCandidateChunks; k::Int = 60)\n\nCalculates joint ranking via the reciprocal rank fusion algorithm. Utility wrapper for hybrid MultiIndex that wraps embeddings and keywords for the SAME CHUNKS!!\n\n!! It only works for two indices with the exact same chunks and chunk positions\n\nExample\n\n# start with document positions and scores from two indices\npositions1 = [1, 3, 5, 7, 9]\nscores1 = [0.9, 0.8, 0.7, 0.6, 0.5]\npositions2 = [2, 4, 6, 8, 10]\nscores2 = [0.5, 0.6, 0.7, 0.8, 0.9]\n\n# mimic the MultiCandidateChunks struct as if it came from :index1a and :index1b\nmcc = RT.MultiCandidateChunks(\n\tvcat(fill(:index1a, length(positions1)), fill(:index1b, length(positions2))),\n\tvcat(positions1, positions2),\n\tvcat(scores1, scores2))\n\nmcc_merged = reciprocal_rank_fusion(mcc; k = 60)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.reciprocal_rank_fusion-Union{Tuple{T}, Tuple{AbstractVector{<:Integer}, AbstractVector{<:T}, AbstractVector{<:Integer}, AbstractVector{<:T}}} where T<:Real","page":"API Reference","title":"RAGTools.reciprocal_rank_fusion","text":"reciprocal_rank_fusion(\n\tpositions1::AbstractVector{<:Integer}, scores1::AbstractVector{<:T},\n\tpositions2::AbstractVector{<:Integer},\n\tscores2::AbstractVector{<:T}; k::Int = 60) where {T <: Real}\n\nMerges two sets of rankings and their joint scores. Calculates the reciprocal rank score for each chunk (discounted by the inverse of the rank).\n\nExample\n\npositions1 = [1, 3, 5, 7, 9]\nscores1 = [0.9, 0.8, 0.7, 0.6, 0.5]\npositions2 = [2, 4, 6, 8, 10]\nscores2 = [0.5, 0.6, 0.7, 0.8, 0.9]\n\nmerged_pos, scores_dict = reciprocal_rank_fusion(positions1, scores1, positions2, scores2; k = 60)\n\n# Create a CandidateChunks from the merged positions and scores\ncc = CandidateChunks(:my_index, merged_pos, [scores_dict[pos] for pos in merged_pos])\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.refine!-Tuple{RAGTools.NoRefiner, RAGTools.AbstractDocumentIndex, RAGTools.AbstractRAGResult}","page":"API Reference","title":"RAGTools.refine!","text":"refine!(\n\trefiner::NoRefiner, index::AbstractChunkIndex, result::AbstractRAGResult;\n\tkwargs...)\n\nSimple no-op function for refine!. It simply copies the result.answer and result.conversations[:answer] without any changes.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.refine!-Tuple{RAGTools.SimpleRefiner, RAGTools.AbstractDocumentIndex, RAGTools.AbstractRAGResult}","page":"API Reference","title":"RAGTools.refine!","text":"refine!(\n\trefiner::SimpleRefiner, index::AbstractDocumentIndex, result::AbstractRAGResult;\n\tverbose::Bool = true,\n\tmodel::AbstractString = PT.MODEL_CHAT,\n\ttemplate::Symbol = :RAGAnswerRefiner,\n\tcost_tracker = Threads.Atomic{Float64}(0.0),\n\tkwargs...)\n\nGive model a chance to refine the answer (using the same or different context than previously provided).\n\nThis method uses the same context as the original answer, however, it can be modified to do additional retrieval and use a different context.\n\nReturns\n\nMutated result with result.final_answer and the full conversation saved in result.conversations[:final_answer]\n\nArguments\n\nrefiner::SimpleRefiner: The method to use for refining the answer. Uses aigenerate.\nindex::AbstractDocumentIndex: The index containing chunks and sources.\nresult::AbstractRAGResult: The result containing the context and question to generate the answer for.\nmodel::AbstractString: The model to use for generating the answer. Defaults to PT.MODEL_CHAT.\nverbose::Bool: If true, enables verbose logging.\ntemplate::Symbol: The template to use for the aigenerate function. Defaults to :RAGAnswerRefiner.\ncost_tracker: An atomic counter to track the cost of the operation.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.refine!-Tuple{RAGTools.TavilySearchRefiner, RAGTools.AbstractDocumentIndex, RAGTools.AbstractRAGResult}","page":"API Reference","title":"RAGTools.refine!","text":"refine!(\n\trefiner::TavilySearchRefiner, index::AbstractDocumentIndex, result::AbstractRAGResult;\n\tverbose::Bool = true,\n\tmodel::AbstractString = PT.MODEL_CHAT,\n\tinclude_answer::Bool = true,\n\tmax_results::Integer = 5,\n\tinclude_domains::AbstractVector{<:AbstractString} = String[],\n\texclude_domains::AbstractVector{<:AbstractString} = String[],\n\ttemplate::Symbol = :RAGWebSearchRefiner,\n\tcost_tracker = Threads.Atomic{Float64}(0.0),\n\tkwargs...)\n\nRefines the answer by executing a web search using the Tavily API. This method aims to enhance the answer's accuracy and relevance by incorporating information retrieved from the web.\n\nNote: The web results and web answer (if requested) will be added to the context and sources!\n\nReturns\n\nMutated result with result.final_answer and the full conversation saved in result.conversations[:final_answer].\nIn addition, the web results and web answer (if requested) are appended to the result.context and result.sources for correct highlighting and verification.\n\nArguments\n\nrefiner::TavilySearchRefiner: The method to use for refining the answer. Uses aigenerate with a web search template.\nindex::AbstractDocumentIndex: The index containing chunks and sources.\nresult::AbstractRAGResult: The result containing the context and question to generate the answer for.\nmodel::AbstractString: The model to use for generating the answer. Defaults to PT.MODEL_CHAT.\ninclude_answer::Bool: If true, includes the answer from Tavily in the web search.\nmax_results::Integer: The maximum number of results to return.\ninclude_domains::AbstractVector{<:AbstractString}: A list of domains to include in the search results. Default is an empty list.\nexclude_domains::AbstractVector{<:AbstractString}: A list of domains to exclude from the search results. Default is an empty list.\nverbose::Bool: If true, enables verbose logging.\ntemplate::Symbol: The template to use for the aigenerate function. Defaults to :RAGWebSearchRefiner.\ncost_tracker: An atomic counter to track the cost of the operation.\n\nExample\n\nrefiner!(TavilySearchRefiner(), index, result)\n# See result.final_answer or pprint(result)\n\nTo enable this refiner in a full RAG pipeline, simply swap the component in the config:\n\ncfg = RT.RAGConfig()\ncfg.generator.refiner = RT.TavilySearchRefiner()\n\nresult = airag(cfg, index; question, return_all = true)\npprint(result)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.rephrase-Tuple{RAGTools.HyDERephraser, AbstractString}","page":"API Reference","title":"RAGTools.rephrase","text":"rephrase(rephraser::SimpleRephraser, question::AbstractString;\n\tverbose::Bool = true,\n\tmodel::String = PT.MODEL_CHAT, template::Symbol = :RAGQueryHyDE,\n\tcost_tracker = Threads.Atomic{Float64}(0.0))\n\nRephrases the question using the provided rephraser template = RAGQueryHyDE.\n\nSpecial flavor of rephrasing using HyDE (Hypothetical Document Embedding) method,  which aims to find the documents most similar to a synthetic passage that would be a good answer to our question.\n\nReturns both the original and the rephrased question.\n\nArguments\n\nrephraser: Type that dictates the logic of rephrasing step.\nquestion: The question to be rephrased.\nmodel: The model to use for rephrasing. Default is PT.MODEL_CHAT.\ntemplate: The rephrasing template to use. Default is :RAGQueryHyDE. Find more with aitemplates(\"rephrase\").\nverbose: A boolean flag indicating whether to print verbose logging. Default is true.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.rephrase-Tuple{RAGTools.NoRephraser, AbstractString}","page":"API Reference","title":"RAGTools.rephrase","text":"rephrase(rephraser::NoRephraser, question::AbstractString; kwargs...)\n\nNo-op, simple passthrough.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.rephrase-Tuple{RAGTools.SimpleRephraser, AbstractString}","page":"API Reference","title":"RAGTools.rephrase","text":"rephrase(rephraser::SimpleRephraser, question::AbstractString;\n\tverbose::Bool = true,\n\tmodel::String = PT.MODEL_CHAT, template::Symbol = :RAGQueryOptimizer,\n\tcost_tracker = Threads.Atomic{Float64}(0.0), kwargs...)\n\nRephrases the question using the provided rephraser template.\n\nReturns both the original and the rephrased question.\n\nArguments\n\nrephraser: Type that dictates the logic of rephrasing step.\nquestion: The question to be rephrased.\nmodel: The model to use for rephrasing. Default is PT.MODEL_CHAT.\ntemplate: The rephrasing template to use. Default is :RAGQueryOptimizer. Find more with aitemplates(\"rephrase\").\nverbose: A boolean flag indicating whether to print verbose logging. Default is true.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.rerank-Tuple{RAGTools.CohereReranker, RAGTools.AbstractDocumentIndex, AbstractString, RAGTools.AbstractCandidateChunks}","page":"API Reference","title":"RAGTools.rerank","text":"rerank(\n\treranker::CohereReranker, \n\tindex::AbstractDocumentIndex, \n\tquestion::AbstractString,\n\tcandidates::AbstractCandidateChunks;\n\tverbose::Bool = false,\n\tapi_key::AbstractString = PT.COHERE_API_KEY,\n\ttop_n::Integer = length(candidates.scores),\n\tmodel::AbstractString = \"rerank-english-v3.0\",\n\treturn_documents::Bool = false,\n\tcost_tracker = Threads.Atomic{Float64}(0.0),\n\tkwargs...\n)\n\nRe-ranks a list of candidate chunks using the Cohere Rerank API. See https://cohere.com/rerank for more details. \n\nArguments\n\nreranker: Using Cohere API\nindex: The index that holds the underlying chunks to be re-ranked.\nquestion: The query to be used for the search.\ncandidates: The candidate chunks to be re-ranked.\ntop_n: The number of most relevant documents to return. Default is length(documents).\nmodel: The model to use for reranking. Default is rerank-english-v3.0.\nreturn_documents: A boolean flag indicating whether to return the reranked documents in the response. Default is false.\nverbose: A boolean flag indicating whether to print verbose logging. Default is false.\ncost_tracker: An atomic counter to track the cost of the retrieval. Not implemented /tracked (cost unclear). Provided for consistency.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.rerank-Tuple{RAGTools.RankGPTReranker, RAGTools.AbstractDocumentIndex, AbstractString, RAGTools.AbstractCandidateChunks}","page":"API Reference","title":"RAGTools.rerank","text":"rerank(\n\treranker::RankGPTReranker, \n\tindex::AbstractDocumentIndex, \n\tquestion::AbstractString,\n\tcandidates::AbstractCandidateChunks;\n\tapi_key::AbstractString = PT.OPENAI_API_KEY,\n\tmodel::AbstractString = PT.MODEL_CHAT,\n\tverbose::Bool = false,\n\ttop_n::Integer = length(candidates.scores),\n\tunique_chunks::Bool = true,\n\tcost_tracker = Threads.Atomic{Float64}(0.0),\n\tkwargs...\n)\n\nRe-ranks a list of candidate chunks using the RankGPT algorithm. See https://github.com/sunnweiwei/RankGPT for more details. \n\nIt uses LLM calls to rank the candidate chunks.\n\nArguments\n\nreranker: Using Cohere API\nindex: The index that holds the underlying chunks to be re-ranked.\nquestion: The query to be used for the search.\ncandidates: The candidate chunks to be re-ranked.\ntop_n: The number of most relevant documents to return. Default is length(documents).\nmodel: The model to use for reranking. Default is rerank-english-v3.0.\nverbose: A boolean flag indicating whether to print verbose logging. Default is 1.\nunique_chunks: A boolean flag indicating whether to remove duplicates from the candidate chunks prior to reranking (saves compute time). Default is true.\n\nExamples\n\nindex = <some index>\nquestion = \"What are the best practices for parallel computing in Julia?\"\n\ncfg = RAGConfig(; retriever = SimpleRetriever(; reranker = RT.RankGPTReranker()))\nmsg = airag(cfg, index; question, return_all = true)\n\nTo get full verbosity of logs, set verbose = 5 (anything higher than 3).\n\nmsg = airag(cfg, index; question, return_all = true, verbose = 5)\n\nReference\n\n[1] Is ChatGPT Good at Search? Investigating Large Language Models as Re-Ranking Agents by W. Sun et al. [2] RankGPT Github\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.retrieve-Tuple{RAGTools.AbstractRetriever, RAGTools.AbstractDocumentIndex, AbstractString}","page":"API Reference","title":"RAGTools.retrieve","text":"retrieve(\n\tretriever::AbstractRetriever,\n\tindex::AbstractChunkIndex,\n\tquestion::AbstractString;\n\tverbose::Integer = 1,\n\ttop_k::Integer = 100,\n\ttop_n::Integer = 5,\n\tapi_kwargs::NamedTuple = NamedTuple(),\n\trephraser::AbstractRephraser = retriever.rephraser,\n\trephraser_kwargs::NamedTuple = NamedTuple(),\n\tembedder::AbstractEmbedder = retriever.embedder,\n\tembedder_kwargs::NamedTuple = NamedTuple(),\n\tprocessor::AbstractProcessor = retriever.processor,\n\tprocessor_kwargs::NamedTuple = NamedTuple(),\n\tfinder::AbstractSimilarityFinder = retriever.finder,\n\tfinder_kwargs::NamedTuple = NamedTuple(),\n\ttagger::AbstractTagger = retriever.tagger,\n\ttagger_kwargs::NamedTuple = NamedTuple(),\n\tfilter::AbstractTagFilter = retriever.filter,\n\tfilter_kwargs::NamedTuple = NamedTuple(),\n\treranker::AbstractReranker = retriever.reranker,\n\treranker_kwargs::NamedTuple = NamedTuple(),\n\tcost_tracker = Threads.Atomic{Float64}(0.0),\n\tkwargs...,\n)\n\nRetrieves the most relevant chunks from the index for the given question and returns them in the RAGResult object.\n\nThis is the main entry point for the retrieval stage of the RAG pipeline. It is often followed by generate! step.\n\nNotes:\n\nThe default flow is build_context! -> answer! -> refine! -> postprocess!.\n\nThe arguments correspond to the steps of the retrieval process (rephrasing, embedding, finding similar docs, tagging, filtering by tags, reranking). You can customize each step by providing a new custom type that dispatches the corresponding function,  \teg, create your own type struct MyReranker<:AbstractReranker end and define the custom method for it rerank(::MyReranker,...) = ....\n\nNote: Discover available retrieval sub-types for each step with subtypes(AbstractRephraser) and similar for other abstract types.\n\nIf you're using locally-hosted models, you can pass the api_kwargs with the url field set to the model's URL and make sure to provide corresponding  \tmodel kwargs to rephraser, embedder, and tagger to use the custom models (they make AI calls).\n\nArguments\n\nretriever: The retrieval method to use. Default is SimpleRetriever but could be AdvancedRetriever for more advanced retrieval.\nindex: The index that holds the chunks and sources to be retrieved from.\nquestion: The question to be used for the retrieval.\nverbose: If >0, it prints out verbose logging. Default is 1. If you set it to 2, it will print out logs for each sub-function.\ntop_k: The TOTAL number of closest chunks to return from find_closest. Default is 100.  If there are multiple rephrased questions, the number of chunks per each item will be top_k  number_of_rephrased_questions.\ntop_n: The TOTAL number of most relevant chunks to return for the context (from rerank step). Default is 5.\napi_kwargs: Additional keyword arguments to be passed to the API calls (shared by all ai* calls).\nrephraser: Transform the question into one or more questions. Default is retriever.rephraser.\nrephraser_kwargs: Additional keyword arguments to be passed to the rephraser.\n\n- `model`: The model to use for rephrasing. Default is `PT.MODEL_CHAT`.\n- `template`: The rephrasing template to use. Default is `:RAGQueryOptimizer` or `:RAGQueryHyDE` (depending on the `rephraser` selected).\n\nembedder: The embedding method to use. Default is retriever.embedder.\nembedder_kwargs: Additional keyword arguments to be passed to the embedder.\nprocessor: The processor method to use when using Keyword-based index. Default is retriever.processor.\nprocessor_kwargs: Additional keyword arguments to be passed to the processor.\nfinder: The similarity search method to use. Default is retriever.finder, often CosineSimilarity.\nfinder_kwargs: Additional keyword arguments to be passed to the similarity finder.\ntagger: The tag generating method to use. Default is retriever.tagger.\ntagger_kwargs: Additional keyword arguments to be passed to the tagger. Noteworthy arguments:\n\n- `tags`: Directly provide the tags to use for filtering (can be String, Regex, or Vector{String}). Useful for `tagger = PassthroughTagger`.\n\nfilter: The tag matching method to use. Default is retriever.filter.\nfilter_kwargs: Additional keyword arguments to be passed to the tag filter.\nreranker: The reranking method to use. Default is retriever.reranker.\nreranker_kwargs: Additional keyword arguments to be passed to the reranker.\n\n- `model`: The model to use for reranking. Default is `rerank-english-v2.0` if you use `reranker = CohereReranker()`.\n\ncost_tracker: An atomic counter to track the cost of the retrieval. Default is Threads.Atomic{Float64}(0.0).\n\nSee also: SimpleRetriever, AdvancedRetriever, build_index, rephrase, get_embeddings, get_keywords, find_closest, get_tags, find_tags, rerank, RAGResult.\n\nExamples\n\nFind the 5 most relevant chunks from the index for the given question.\n\n# assumes you have an existing index `index`\nretriever = SimpleRetriever()\n\nresult = retrieve(retriever,\n\tindex,\n\t\"What is the capital of France?\",\n\ttop_n = 5)\n\n# or use the default retriever (same as above)\nresult = retrieve(retriever,\n\tindex,\n\t\"What is the capital of France?\",\n\ttop_n = 5)\n\nApply more advanced retrieval with question rephrasing and reranking (requires COHERE_API_KEY). We will obtain top 100 chunks from embeddings (top_k) and top 5 chunks from reranking (top_n).\n\nretriever = AdvancedRetriever()\n\nresult = retrieve(retriever, index, question; top_k=100, top_n=5)\n\nYou can use the retriever to customize your retrieval strategy or directly change the strategy types in the retrieve kwargs!\n\nExample of using locally-hosted model hosted on localhost:8080:\n\nretriever = SimpleRetriever()\nresult = retrieve(retriever, index, question;\n\trephraser_kwargs = (; model = \"custom\"),\n\tembedder_kwargs = (; model = \"custom\"),\n\ttagger_kwargs = (; model = \"custom\"), api_kwargs = (;\n\t\turl = \"http://localhost:8080\"))\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.run_qa_evals-Tuple{RAGTools.AbstractChunkIndex, AbstractVector{<:RAGTools.QAEvalItem}}","page":"API Reference","title":"RAGTools.run_qa_evals","text":"run_qa_evals(index::AbstractChunkIndex, qa_items::AbstractVector{<:QAEvalItem};\n\tapi_kwargs::NamedTuple = NamedTuple(),\n\tairag_kwargs::NamedTuple = NamedTuple(),\n\tqa_evals_kwargs::NamedTuple = NamedTuple(),\n\tverbose::Bool = true, parameters_dict::Dict{Symbol, <:Any} = Dict{Symbol, Any}())\n\nEvaluates a vector of QAEvalItems and returns a vector QAEvalResult.  This function assesses the relevance and accuracy of the answers generated in a QA evaluation context.\n\nSee ?run_qa_evals for more details.\n\nArguments\n\nqa_items::AbstractVector{<:QAEvalItem}: The vector of QA evaluation items containing the questions and their answers.\nverbose::Bool: If true, enables verbose logging. Defaults to true.\napi_kwargs::NamedTuple: Parameters that will be forwarded to the API calls. See ?aiextract for details.\nairag_kwargs::NamedTuple: Parameters that will be forwarded to airag calls. See ?airag for details.\nqa_evals_kwargs::NamedTuple: Parameters that will be forwarded to run_qa_evals calls. See ?run_qa_evals for details.\nparameters_dict::Dict{Symbol, Any}: Track any parameters used for later evaluations. Keys must be Symbols.\n\nReturns\n\nVector{QAEvalResult}: Vector of evaluation results that includes various scores and metadata related to the QA evaluation.\n\nExample\n\nindex = \"...\" # Assuming a proper index is defined\nqa_items = [QAEvalItem(question=\"What is the capital of France?\", answer=\"Paris\", context=\"France is a country in Europe.\"),\n\t\t\tQAEvalItem(question=\"What is the capital of Germany?\", answer=\"Berlin\", context=\"Germany is a country in Europe.\")]\n\n# Let's run a test with `top_k=5`\nresults = run_qa_evals(index, qa_items; airag_kwargs=(;top_k=5), parameters_dict=Dict(:top_k => 5))\n\n# Filter out the \"failed\" calls\nresults = filter(x->!isnothing(x.answer_score), results);\n\n# See average judge score\nmean(x->x.answer_score, results)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.run_qa_evals-Tuple{RAGTools.QAEvalItem, RAGResult}","page":"API Reference","title":"RAGTools.run_qa_evals","text":"run_qa_evals(qa_item::QAEvalItem, ctx::RAGResult; verbose::Bool = true,\n\t\t\t parameters_dict::Dict{Symbol, <:Any}, judge_template::Symbol = :RAGJudgeAnswerFromContext,\n\t\t\t model_judge::AbstractString, api_kwargs::NamedTuple = NamedTuple()) -> QAEvalResult\n\nEvaluates a single QAEvalItem using RAG details (RAGResult) and returns a QAEvalResult structure. This function assesses the relevance and accuracy of the answers generated in a QA evaluation context.\n\nArguments\n\nqa_item::QAEvalItem: The QA evaluation item containing the question and its answer.\nctx::RAGResult: The RAG result used for generating the QA pair, including the original context and the answers. Comes from airag(...; return_context=true)\nverbose::Bool: If true, enables verbose logging. Defaults to true.\nparameters_dict::Dict{Symbol, Any}: Track any parameters used for later evaluations. Keys must be Symbols.\njudge_template::Symbol: The template symbol for the AI model used to judge the answer. Defaults to :RAGJudgeAnswerFromContext.\nmodel_judge::AbstractString: The AI model used for judging the answer's quality.  Defaults to standard chat model, but it is advisable to use more powerful model GPT-4.\napi_kwargs::NamedTuple: Parameters that will be forwarded to the API endpoint.\n\nReturns\n\nQAEvalResult: An evaluation result that includes various scores and metadata related to the QA evaluation.\n\nNotes\n\nThe function computes a retrieval score and rank based on how well the context matches the QA context.\nIt then uses the judge_template and model_judge to score the answer's accuracy and relevance.\nIn case of errors during evaluation, the function logs a warning (if verbose is true) and the answer_score will be set to nothing.\n\nExamples\n\nEvaluating a QA pair using a specific context and model:\n\nqa_item = QAEvalItem(question=\"What is the capital of France?\", answer=\"Paris\", context=\"France is a country in Europe.\")\nctx = RAGResult(source=\"Wikipedia\", context=\"France is a country in Europe.\", answer=\"Paris\")\nparameters_dict = Dict(\"param1\" => \"value1\", \"param2\" => \"value2\")\n\neval_result = run_qa_evals(qa_item, ctx, parameters_dict=parameters_dict, model_judge=\"MyAIJudgeModel\")\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.score_retrieval_hit-Tuple{AbstractString, Vector{<:AbstractString}}","page":"API Reference","title":"RAGTools.score_retrieval_hit","text":"Returns 1.0 if context overlaps or is contained within any of the candidate_context\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.score_retrieval_rank-Tuple{AbstractString, Vector{<:AbstractString}}","page":"API Reference","title":"RAGTools.score_retrieval_rank","text":"Returns Integer rank of the position where context overlaps or is contained within a candidate_context\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.score_to_unit_scale-Union{Tuple{AbstractVector{T}}, Tuple{T}} where T<:Real","page":"API Reference","title":"RAGTools.score_to_unit_scale","text":"score_to_unit_scale(x::AbstractVector{T}) where T<:Real\n\nShift and scale a vector of scores to the unit scale [0, 1].\n\nExample\n\nx = [1.0, 2.0, 3.0, 4.0, 5.0]\nscaled_x = score_to_unit_scale(x)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.set_node_style!-Tuple{TrigramAnnotater, RAGTools.AnnotatedNode}","page":"API Reference","title":"RAGTools.set_node_style!","text":"set_node_style!(::TrigramAnnotater, node::AnnotatedNode;\n\tlow_threshold::Float64 = 0.0, medium_threshold::Float64 = 0.5, high_threshold::Float64 = 1.0,\n\tdefault_styler::AbstractAnnotationStyler = Styler(),\n\tlow_styler::AbstractAnnotationStyler = Styler(color = :magenta, bold = false),\n\tmedium_styler::AbstractAnnotationStyler = Styler(color = :blue, bold = false),\n\thigh_styler::AbstractAnnotationStyler = Styler(color = :nothing, bold = false),\n\tbold_multihits::Bool = false)\n\nSets style of node based on the provided rules\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.setpropertynested-Tuple{NamedTuple, Vector{Symbol}, Symbol, Any}","page":"API Reference","title":"RAGTools.setpropertynested","text":"setpropertynested(nt::NamedTuple, parent_keys::Vector{Symbol},\n\tkey::Symbol,\n\tvalue\n\n)\n\nSetter for a property key in a nested NamedTuple nt, where the property is nested to a key in parent_keys.\n\nUseful for nested kwargs where we want to change some property in parent_keys subset (eg, model in retriever_kwargs).\n\nExamples\n\nkw = (; abc = (; def = \"x\"))\nsetpropertynested(kw, [:abc], :def, \"y\")\n# Output: (abc = (def = \"y\",),)\n\nPractical example of changing all model keys in CHAT-based steps in the pipeline:\n\n# changes :model to \"gpt4t\" whenever the parent key is in the below list (chat-based steps)\nsetpropertynested(kwargs,\n\t[:rephraser_kwargs, :tagger_kwargs, :answerer_kwargs, :refiner_kwargs],\n\t:model, \"gpt4t\")\n\nOr changing an embedding model (across both indexer and retriever steps, because it's same step name):\n\nkwargs = setpropertynested(\n\t\tkwargs, [:embedder_kwargs],\n\t\t:model, \"text-embedding-3-large\"\n\t)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.split_into_code_and_sentences-Tuple{Union{SubString{String}, String}}","page":"API Reference","title":"RAGTools.split_into_code_and_sentences","text":"split_into_code_and_sentences(input::Union{String, SubString{String}})\n\nSplits text block into code or text and sub-splits into units.\n\nIf code block, it splits by newline but keep the group_id the same (to have the same source) If text block, splits into sentences, bullets, etc., provides different group_id (to have different source)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.tags_extract-Tuple{RAGTools.Tag}","page":"API Reference","title":"RAGTools.tags_extract","text":"tags_extract(item::Tag)\ntags_extract(tags::Vector{Tag})\n\nExtracts the Tag item into a string of the form category:::value (lowercased and spaces replaced with underscores).\n\nExample\n\nmsg = aiextract(:RAGExtractMetadataShort; return_type=MaybeTags, text=\"I like package DataFrames\", instructions=\"None.\")\nmetadata = tags_extract(msg.content.items)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.tavily_api-Tuple{}","page":"API Reference","title":"RAGTools.tavily_api","text":"tavily_api(;\n\tapi_key::AbstractString,\n\tendpoint::String = \"search\",\n\turl::AbstractString = \"https://api.tavily.com\",\n\thttp_kwargs::NamedTuple = NamedTuple(),\n\tkwargs...)\n\nSends API requests to Tavily and returns the response.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.tf-Tuple{RAGTools.AbstractDocumentTermMatrix}","page":"API Reference","title":"RAGTools.tf","text":"tf(dtm::AbstractDocumentTermMatrix)\n\nGet the term frequency matrix of an AbstractDocumentTermMatrix.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.token_with_boundaries-Tuple{Union{Nothing, AbstractString}, AbstractString, Union{Nothing, AbstractString}}","page":"API Reference","title":"RAGTools.token_with_boundaries","text":"token_with_boundaries(\n\tprev_token::Union{Nothing, AbstractString}, curr_token::AbstractString,\n\tnext_token::Union{Nothing, AbstractString})\n\nJoins the three tokens together. Useful to add boundary tokens (like spaces vs brackets) to the curr_token to improve the matched context (ie, separate partial matches from exact match)\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.tokenize-Tuple{Union{SubString{String}, String}}","page":"API Reference","title":"RAGTools.tokenize","text":"tokenize(input::Union{String, SubString{String}})\n\nTokenizes provided input by spaces, special characters or Julia symbols (eg, =>).\n\nUnlike other tokenizers, it aims to lossless - ie, keep both the separated text and the separators.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.translate_positions_to_parent-Tuple{RAGTools.AbstractChunkIndex, AbstractVector{<:Integer}}","page":"API Reference","title":"RAGTools.translate_positions_to_parent","text":"translate_positions_to_parent(index::AbstractChunkIndex, positions::AbstractVector{<:Integer})\n\nTranslate positions to the parent index. Useful to convert between positions in a view and the original index.\n\nUsed whenever a chunkdata() is used to re-align positions in case index is a view.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.translate_positions_to_parent-Tuple{SubChunkIndex, AbstractVector{<:Integer}}","page":"API Reference","title":"RAGTools.translate_positions_to_parent","text":"translate_positions_to_parent(\n\tindex::SubChunkIndex, pos::AbstractVector{<:Integer})\n\nTranslate positions to the parent index. Useful to convert between positions in a view and the original index.\n\nUsed whenever a chunkdata() or tags() are used to re-align positions to the \"parent\" index.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.trigram_support!-Union{Tuple{F2}, Tuple{F1}, Tuple{RAGTools.AnnotatedNode, AbstractVector}, Tuple{RAGTools.AnnotatedNode, AbstractVector, F1}, Tuple{RAGTools.AnnotatedNode, AbstractVector, F1, F2}} where {F1<:Function, F2<:Function}","page":"API Reference","title":"RAGTools.trigram_support!","text":"trigram_support!(parent_node::AnnotatedNode,\n\tcontext_trigrams::AbstractVector, trigram_func::F1 = trigrams, token_transform::F2 = identity;\n\tskip_trigrams::Bool = false, min_score::Float64 = 0.5,\n\tmin_source_score::Float64 = 0.25,\n\tstop_words::AbstractVector{<:String} = STOPWORDS,\n\tstyler_kwargs...) where {F1 <: Function, F2 <: Function}\n\nFind if the parent_node.content is supported by the provided context_trigrams.\n\nLogic:\n\nSplit the parent_node.content into tokens\nCreate an AnnotatedNode for each token\nIf skip_trigrams is enabled, it looks for an exact match in the context_trigrams\nIf no exact match found, it counts trigram-based match (include the surrounding tokens for better contextual awareness) as a score\nThen it sets the style of the node based on the score\nLastly, it aligns the styles of neighboring nodes with score==nothing (eg, single character tokens)\nThen, it rolls up the scores and sources to the parent node\n\nFor diagnostics, you can use AbstractTrees.print_tree(parent_node) to see the tree structure of each token and its score.\n\nExample\n\n```julia contexttrigrams = textto_trigrams.([\"This IS a test.\", \"Another test.\", \t\"More content here.\"])\n\nnode = AnnotatedNode(content = \"xyz\")  trigramsupport!(node, contexttrigrams) # updates node.children! `\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.trigrams-Tuple{AbstractString}","page":"API Reference","title":"RAGTools.trigrams","text":"trigrams(input_string::AbstractString; add_word::AbstractString = \"\")\n\nSplits provided input_string into a vector of trigrams (combination of three consecutive characters found in the input_string).\n\nIf add_word is provided, it is added to the resulting array. Useful to add the full word itself to the resulting array for exact match.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.trigrams_hashed-Tuple{AbstractString}","page":"API Reference","title":"RAGTools.trigrams_hashed","text":"trigrams_hashed(input_string::AbstractString; add_word::AbstractString = \"\")\n\nSplits provided input_string into a Set of hashed trigrams (combination of three consecutive characters found in the input_string).\n\nIt is more efficient for lookups in large strings (eg, >100K characters).\n\nIf add_word is provided, it is added to the resulting array to hash. Useful to add the full word itself to the resulting array for exact match.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.vocab-Tuple{RAGTools.AbstractDocumentTermMatrix}","page":"API Reference","title":"RAGTools.vocab","text":"vocab(dtm::AbstractDocumentTermMatrix)\n\nGet the vocabulary vector of an AbstractDocumentTermMatrix, defined in rag_interface.jl.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#RAGTools.vocab_lookup-Tuple{RAGTools.AbstractDocumentTermMatrix}","page":"API Reference","title":"RAGTools.vocab_lookup","text":"vocab_lookup(dtm::AbstractDocumentTermMatrix)\n\nGet the vocabulary lookup dictionary of an AbstractDocumentTermMatrix.\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#StructTypes.constructfrom-Tuple{Type{RAGResult}, Union{Dict, JSON3.Object}}","page":"API Reference","title":"StructTypes.constructfrom","text":"StructTypes.constructfrom(RAGResult, JSON3.read(tmp))\n\nUse as: StructTypes.constructfrom(RAGResult, JSON3.read(tmp))\n\n\n\n\n\n","category":"method"},{"location":"api_reference/#StructTypes.constructfrom-Union{Tuple{T}, Tuple{Type{T}, Union{Dict, JSON3.Object}}} where T<:Union{CandidateChunks, MultiCandidateChunks}","page":"API Reference","title":"StructTypes.constructfrom","text":"StructTypes.constructfrom(\n\t::Type{T},\n\tobj::Union{Dict, JSON3.Object}\n) where {T <: Union{CandidateChunks, MultiCandidateChunks}}\n\nConstructor for serialization - opinionated for abstract types!\n\n\n\n\n\n","category":"method"},{"location":"interface/#RAG-Interface","page":"Interface","title":"RAG Interface","text":"","category":"section"},{"location":"interface/#System-Overview","page":"Interface","title":"System Overview","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"This system is designed for information retrieval and response generation, structured in three main phases:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Preparation, when you create an instance of AbstractIndex\nRetrieval, when you surface the top most relevant chunks/items in the index and return AbstractRAGResult, which contains the references to the chunks (AbstractCandidateChunks)\nGeneration, when you generate an answer based on the context built from the retrieved chunks, return either AIMessage or AbstractRAGResult","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"The corresponding functions are build_index, retrieve, and generate!, respectively. Here is the high-level diagram that shows the signature of the main functions:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"(Image: RAG Diagram High-level)","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Notice that the first argument is a custom type for multiple dispatch.  In addition, observe the \"kwargs\" names, that's how the keyword arguments for each function are passed down from the higher-level functions (eg, build_index(...; chunker_kwargs=(; separators=...)))). It's the simplest way to customize some step of the pipeline (eg, set a custom model with a model kwarg or prompt template with template kwarg).","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"The system is designed to be hackable and extensible at almost every entry point. If you want to customize the behavior of any step, you can do so by defining a new type and defining a new method for the step you're changing, eg, ","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"using RAGTools: rerank\n\nstruct MyReranker <: AbstractReranker end\nrerank(::MyReranker, index, candidates) = ...","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"And then you would set the retrive step to use your custom MyReranker via reranker kwarg, eg, retrieve(....; reranker = MyReranker()) (or customize the main dispatching AbstractRetriever struct).","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"The overarching principles are:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Always dispatch / customize the behavior by defining a new Struct and the corresponding method for the existing functions (eg, rerank function for the re-ranking step).\nCustom types are provided as the first argument (the high-level functions will work without them as we provide some defaults).\nCustom types do NOT have any internal fields or DATA (with the exception of managing sub-steps of the pipeline like AbstractRetriever or RAGConfig). \nAdditional data should be passed around as keyword arguments (eg, chunker_kwargs in build_index to pass data to the chunking step). The intention was to have some clearly documented default values in the docstrings of each step + to have the various options all in one place.","category":"page"},{"location":"interface/#RAG-Diagram","page":"Interface","title":"RAG Diagram","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"(Image: RAG Diagram Detailed)","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"The main functions are:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Prepare your document index with build_index:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"signature: (indexer::AbstractIndexBuilder, files_or_docs::Vector{<:AbstractString}) -> AbstractChunkIndex\nflow: get_chunks -> get_embeddings -> get_tags -> build_tags\ndispatch types: AbstractIndexBuilder, AbstractChunker, AbstractEmbedder, AbstractTagger","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Run E2E RAG with airag: ","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"signature: (cfg::AbstractRAGConfig, index::AbstractChunkIndex; question::AbstractString) -> AIMessage or AbstractRAGResult\nflow: retrieve -> generate!\ndispatch types: AbstractRAGConfig, AbstractRetriever, AbstractGenerator","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Retrieve relevant chunks with retrieve:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"signature: (retriever::AbstractRetriever, index::AbstractChunkIndex, question::AbstractString) -> AbstractRAGResult\nflow: rephrase -> get_embeddings -> find_closest -> get_tags -> find_tags -> rerank\ndispatch types: AbstractRAGConfig, AbstractRephraser, AbstractEmbedder, AbstractSimilarityFinder, AbstractTagger, AbstractTagFilter, AbstractReranker","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Generate an answer from relevant chunks with generate!:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"signature: (generator::AbstractGenerator, index::AbstractChunkIndex, result::AbstractRAGResult) -> AIMessage or AbstractRAGResult\nflow: build_context! -> answer! -> refine! -> postprocess!\ndispatch types: AbstractGenerator, AbstractContextBuilder, AbstractAnswerer, AbstractRefiner, AbstractPostprocessor","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"To discover the currently available implementations, use subtypes function, eg, subtypes(AbstractReranker).","category":"page"},{"location":"interface/#Passing-Keyword-Arguments","page":"Interface","title":"Passing Keyword Arguments","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"If you need to pass keyword arguments, use the nested kwargs corresponding to the dispatch type names (rephrase step, has rephraser dispatch type and rephraser_kwargs for its keyword arguments).","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"For example:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"cfg = RAGConfig(; retriever = AdvancedRetriever())\n\n# kwargs will be big and nested, let's prepare them upfront\n# we specify \"custom\" model for each component that calls LLM\nkwargs = (\n    retriever = AdvancedRetriever(),\n    retriever_kwargs = (;\n        top_k = 100,\n        top_n = 5,\n        # notice that this is effectively: retriever_kwargs/rephraser_kwargs/template\n        rephraser_kwargs = (;\n            template = :RAGQueryHyDE,\n            model = \"custom\")),\n    generator_kwargs = (;\n        # pass kwargs to `answer!` step defined by the `answerer` -> we're setting `answerer_kwargs`\n        answerer_kwargs = (;\n            model = \"custom\"),\n    # api_kwargs can be shared across all components\n    api_kwargs = (;\n        url = \"http://localhost:8080\")))\n\nresult = airag(cfg, index, question; kwargs...)","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"If you were one level deeper in the pipeline, working with retriever directly, you would pass:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"retriever_kwargs = (;\n    top_k = 100,\n    top_n = 5,\n    # notice that this is effectively: rephraser_kwargs/template\n    rephraser_kwargs = (;\n      template = :RAGQueryHyDE,\n      model = \"custom\"),\n  # api_kwargs can be shared across all components\n  api_kwargs = (;\n      url = \"http://localhost:8080\"))\n\nresult = retrieve(AdvancedRetriever(), index, question; retriever_kwargs...)","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"And going even deeper, you would provide the rephraser_kwargs directly to the rephrase step, eg,","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"rephrase(SimpleRephraser(), question; model=\"custom\", template = :RAGQueryHyDE, api_kwargs = (; url = \"http://localhost:8080\"))","category":"page"},{"location":"interface/#Deepdive","page":"Interface","title":"Deepdive","text":"","category":"section"},{"location":"interface/","page":"Interface","title":"Interface","text":"Preparation Phase:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Begins with build_index, which creates a user-defined index type from an abstract chunk index using specified dels and function strategies.\nget_chunks then divides the indexed data into manageable pieces based on a chunking strategy.\nget_embeddings generates embeddings for each chunk using an embedding strategy to facilitate similarity arches.\nFinally, get_tags extracts relevant metadata from each chunk, enabling tag-based filtering (hybrid search index). If there are tags available, build_tags is called to build the corresponding sparse matrix for filtering with tags.","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Retrieval Phase:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"The retrieve step is intended to find the most relevant chunks in the index.\nrephrase is called first, if we want to rephrase the query (methods like HyDE can improve retrieval quite a bit)!\nget_embeddings generates embeddings for the original + rephrased query\nfind_closest looks up the most relevant candidates (CandidateChunks) using a similarity search strategy.\nget_tags extracts the potential tags (can be provided as part of the airag call, eg, when we want to use only some small part of the indexed chunks)\nfind_tags filters the candidates to strictly match at least one of the tags (if provided)\nrerank is called to rerank the candidates based on the reranking strategy (ie, to improve the ordering of the chunks in context).","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Generation Phase:","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"The generate! step is intended to generate a response based on the retrieved chunks, provided via AbstractRAGResult (eg, RAGResult).\nbuild_context! constructs the context for response generation based on a context strategy and applies the necessary formatting\nanswer! generates the response based on the context and the query\nrefine! is called to refine the response (optional, defaults to passthrough)\npostprocessing! is available for any final touches to the response or to potentially save or format the results (eg, automatically save to the disk)","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"Note that all generation steps are mutating the RAGResult object.","category":"page"},{"location":"interface/","page":"Interface","title":"Interface","text":"See more details and corresponding functions and types in src/rag_interface.jl.","category":"page"},{"location":"#RAGTools","page":"Home","title":"RAGTools","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"RAGTools.jl is a battle-tested package for building Retrieval-Augmented Generation (RAG) applications in Julia. Originally part of PromptingTools.jl, it has been carved out into a standalone package after proving its value in production use cases for over a year.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The package focuses on high-performance, in-memory RAG pipelines that leverage Julia's speed to avoid the complexity of cloud-hosted vector databases. It seamlessly integrates with PromptingTools.jl to support a wide range of AI models and providers. However, if you need vector database support, you can simply overload the necessary functions in the pipeline (see the RAG Interface section for more details).","category":"page"},{"location":"","page":"Home","title":"Home","text":"If you're curious about some specific features, check out the Features section at the bottom of the page.","category":"page"},{"location":"#Quick-Start","page":"Home","title":"Quick Start","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Import the package:","category":"page"},{"location":"","page":"Home","title":"Home","text":"using RAGTools","category":"page"},{"location":"","page":"Home","title":"Home","text":"Key functions:","category":"page"},{"location":"","page":"Home","title":"Home","text":"build_index: Create a RAG index from documents (returns ChunkIndex)\nairag: Generate answers using RAG (combines retrieve and generate!)\nretrieve: Find relevant document chunks for a question\ngenerate!: Create an answer from retrieved chunks\nannotate_support: Highlight which parts of answers are supported by documents\nbuild_qa_evals: Generate question-answer pairs for evaluating RAG performance","category":"page"},{"location":"#Basic-Example","page":"Home","title":"Basic Example","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Index some documents:","category":"page"},{"location":"","page":"Home","title":"Home","text":"# Create sample documents\nsentences = [\n    \"Find the most comprehensive guide on Julia programming language for beginners published in 2023.\",\n    \"Search for the latest advancements in quantum computing using Julia language.\",\n    \"How to implement machine learning algorithms in Julia with examples.\",\n    \"Looking for performance comparison between Julia, Python, and R for data analysis.\",\n    \"Find Julia language tutorials focusing on high-performance scientific computing.\",\n    \"Search for the top Julia language packages for data visualization and their documentation.\",\n    \"How to set up a Julia development environment on Windows 10.\",\n    \"Discover the best practices for parallel computing in Julia.\",\n    \"Search for case studies of large-scale data processing using Julia.\",\n    \"Find comprehensive resources for mastering metaprogramming in Julia.\",\n    \"Looking for articles on the advantages of using Julia for statistical modeling.\",\n    \"How to contribute to the Julia open-source community: A step-by-step guide.\",\n    \"Find the comparison of numerical accuracy between Julia and MATLAB.\",\n    \"Looking for the latest Julia language updates and their impact on AI research.\",\n    \"How to efficiently handle big data with Julia: Techniques and libraries.\",\n    \"Discover how Julia integrates with other programming languages and tools.\",\n    \"Search for Julia-based frameworks for developing web applications.\",\n    \"Find tutorials on creating interactive dashboards with Julia.\",\n    \"How to use Julia for natural language processing and text analysis.\",\n    \"Discover the role of Julia in the future of computational finance and econometrics.\"\n]\n\n# Build the index\nindex = build_index(sentences; \n    chunker_kwargs=(; sources=map(i -> \"Doc$i\", 1:length(sentences))))","category":"page"},{"location":"","page":"Home","title":"Home","text":"Generate an answer:","category":"page"},{"location":"","page":"Home","title":"Home","text":"# Simple query\nquestion = \"What are the best practices for parallel computing in Julia?\"\nmsg = airag(index; question)\n\n# Get detailed results including intermediate steps (see RAG Interface section to understand the different steps)\nresult = airag(index; question, return_all=true)\n\n# Pretty print with support annotations\npprint(result)","category":"page"},{"location":"#Extending-the-Pipeline","page":"Home","title":"Extending the Pipeline","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The package is designed to be modular and extensible:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Use the default pipeline with SimpleIndexer:","category":"page"},{"location":"","page":"Home","title":"Home","text":"index = build_index(SimpleIndexer(), sentences)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Or customize any step by implementing your own methods:","category":"page"},{"location":"","page":"Home","title":"Home","text":"# Example structure of the pipeline\nresult = retrieve(index, question)  # Get relevant chunks\nresult = generate!(index, result)   # Generate answer","category":"page"},{"location":"","page":"Home","title":"Home","text":"For more advanced usage, see the RAG Interface section that describes the different steps in the pipeline and how to customize them.","category":"page"},{"location":"#\"Citation\"-Annotations","page":"Home","title":"\"Citation\" Annotations","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"RAGTools provides powerful support annotation capabilities through its pretty-printing system. Use pprint to automatically analyze and display how well the generated answer is supported by the source documents:","category":"page"},{"location":"","page":"Home","title":"Home","text":"pprint(result)","category":"page"},{"location":"","page":"Home","title":"Home","text":"Example output (with color highlighting in terminal):","category":"page"},{"location":"","page":"Home","title":"Home","text":"--------------------\nQUESTION(s)\n--------------------\n- What are the best practices for parallel computing in Julia?\n\n--------------------\nANSWER\n--------------------\nSome of the best practices for parallel computing in Julia include:[1,0.7]\n- Using [3,0.4]`@threads` for simple parallelism[1,0.34]\n- Utilizing `Distributed` module for more complex parallel tasks[1,0.19]\n- Avoiding excessive memory allocation\n- Considering task granularity for efficient workload distribution\n\n--------------------\nSOURCES\n--------------------\n1. Doc8\n2. Doc15\n3. Doc5\n4. Doc2\n5. Doc9","category":"page"},{"location":"#Understanding-the-Output","page":"Home","title":"Understanding the Output","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"The annotation system helps you validate the generated answers:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Color Coding:\nUncolored text: High match with source documents\nBlue text: Partial match with sources\nMagenta text: No match (model-generated)\nSource Citations: [3,0.4] indicates source document #3 with 40% match score","category":"page"},{"location":"","page":"Home","title":"Home","text":"For web applications, use print_html to generate HTML-formatted output with styling:","category":"page"},{"location":"","page":"Home","title":"Home","text":"print_html(result)  # Great for Genie.jl/Stipple.jl applications","category":"page"},{"location":"#Features","page":"Home","title":"Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"RAGTools.jl offers a rich set of features for building production-ready RAG applications:","category":"page"},{"location":"","page":"Home","title":"Home","text":"Simple One-Line RAG","category":"page"},{"location":"","page":"Home","title":"Home","text":"Quick setup with build_index and airag functions\nDefault pipeline with semantic search and basic generation\nSeamless integration with PromptingTools.jl for various AI models","category":"page"},{"location":"","page":"Home","title":"Home","text":"Flexible Pipeline Components","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modular pipeline with consistent step names (retrieve, rerank, etc.)\nEach step dispatches on custom types (e.g., inherit from AbstractRetriever, AbstractReranker, etc.) \nEasy to extend by implementing new types and the corresponding methods without changing core pipeline\nDispatching kwarg & configuration always passed as first argument for maximum flexibility","category":"page"},{"location":"#Retrieval-Options","page":"Home","title":"Retrieval Options","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Semantic Search\nCosine similarity with dense embeddings\nBM25 text similarity for keyword-based search\nBinary embeddings with Hamming distance for efficiency\nBit-packed binary embeddings for maximum space efficiency\nHybrid indices combining multiple similarity methods","category":"page"},{"location":"#Advanced-Retrieval-Features","page":"Home","title":"Advanced Retrieval Features","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Query Enhancement\nHYDE (Hypothetical Document Embedding) for query rephrasing\nMultiple query variations for better coverage\nRanking & Fusion\nReciprocal Rank Fusion for combining multiple rankings\nMultiple ranking models:\nLocal ranking with FlashRank.jl\nRankGPT for LLM-based reranking\nCohere Rerank API integration\nCustom ranking model support","category":"page"},{"location":"#Document-Processing","page":"Home","title":"Document Processing","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Chunking & Embedding\nMultiple chunking strategies\nBatched embedding for efficiency\nSupport for various embedding models\nBinary and bit-packed embedding compression\nEmbedding dimension truncation\nTagging & Filtering\nTag-based filtering system\nCustom tag generation support\nFlexible tag matching strategies","category":"page"},{"location":"","page":"Home","title":"Home","text":"Generation & Refinement","category":"page"},{"location":"","page":"Home","title":"Home","text":"Multiple generation strategies\nAnswer refinement steps\nCustomizable post-processing\nSupport for various AI models through PromptingTools.jl","category":"page"},{"location":"","page":"Home","title":"Home","text":"Quality & Analysis","category":"page"},{"location":"","page":"Home","title":"Home","text":"Answer Support Analysis\nAutomatic source citation with [source_id, score] format\nSupport score calculation using trigram matching\nColor-coded fact-checking visualization:\nUncolored: High confidence match with sources\nBlue: Partial match with sources\nMagenta: No source support (model-generated)\nSentence-level support analysis\nSupport threshold customization\nAutomated citation placement\nSource document tracking\nVisual Validation\nPretty printing with color-coded support levels\nHTML output for web applications\nInteractive source exploration\nSupport score distribution analysis\nEvaluation Tools\nAutomated QA pair generation for evaluation\nSupport coverage metrics\nSource utilization analysis\nAnswer consistency checking","category":"page"},{"location":"","page":"Home","title":"Home","text":"Integration & Observability","category":"page"},{"location":"","page":"Home","title":"Home","text":"JSON logging of results and conversations\nIntegration with Spehulak.jl for RAG performance analysis\nCost tracking across API calls\nPerformance metrics and timing","category":"page"},{"location":"","page":"Home","title":"Home","text":"Utility Features","category":"page"},{"location":"","page":"Home","title":"Home","text":"Tokenization utilities\nText splitting functions\nPretty printing with support annotations\nBatch processing utilities\nCost tracking and optimization tools","category":"page"},{"location":"","page":"Home","title":"Home","text":"Extensibility","category":"page"},{"location":"","page":"Home","title":"Home","text":"Modular pipeline design\nCustom component support\nMultiple pre-built configurations:\nSimpleRetriever\nSimpleBM25Retriever\nAdvancedRetriever\nEasy integration with vector databases","category":"page"},{"location":"","page":"Home","title":"Home","text":"Performance Optimization","category":"page"},{"location":"","page":"Home","title":"Home","text":"In-memory operation for speed\nEfficient binary embedding compression\nBatched operations for API calls\nMulti-threading support\nMemory-efficient data structures","category":"page"},{"location":"example/#Building-a-Simple-Retrieval-Augmented-Generation-(RAG)-System-with-RAGTools.jl","page":"Example","title":"Building a Simple Retrieval-Augmented Generation (RAG) System with RAGTools.jl","text":"","category":"section"},{"location":"example/","page":"Example","title":"Example","text":"Let's build a Retrieval-Augmented Generation (RAG) chatbot, tailored to navigate and interact with the DataFrames.jl documentation.  \"RAG\" is probably the most common and valuable pattern in Generative AI at the moment.","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"If you're not familiar with \"RAG\", start with this article.","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"using RAGTools\nusing JSON3, Serialization, DataFramesMeta\nusing Statistics: mean\nconst RT = RAGTools","category":"page"},{"location":"example/#RAG-in-Two-Lines","page":"Example","title":"RAG in Two Lines","text":"","category":"section"},{"location":"example/","page":"Example","title":"Example","text":"Let's put together a few text pages from DataFrames.jl docs.  Simply go to DataFrames.jl docs and copy&paste a few pages into separate text files. Save them in the examples/data folder (see some example pages provided). Ideally, delete all the noise (like headers, footers, etc.) and keep only the text you want to use for the chatbot. Remember, garbage in, garbage out!","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"files = [\n    joinpath(\"examples\", \"data\", \"database_style_joins.txt\"),\n    joinpath(\"examples\", \"data\", \"what_is_dataframes.txt\"),\n]\n# Build an index of chunks, embed them, and create a lookup index of metadata/tags for each chunk\nindex = build_index(files; extract_metadata = false);","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"Let's ask a question","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"# Embeds the question, finds the closest chunks in the index, and generates an answer from the closest chunks\nanswer = airag(index; question = \"I like dplyr, what is the equivalent in Julia?\")","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"AIMessage(\"The equivalent package in Julia to dplyr in R is DataFramesMeta.jl. It provides convenience functions for data manipulation with syntax similar to dplyr.\")","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"First RAG in two lines? Done!","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"What does it do?","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"build_index will chunk the documents into smaller pieces, embed them into numbers (to be able to judge the similarity of chunks) and, optionally, create a lookup index of metadata/tags for each chunk)\nindex is the result of this step and it holds your chunks, embeddings, and other metadata! Just show it :)\nairag will\nembed your question\nfind the closest chunks in the index (use parameters top_k and minimum_similarity to tweak the \"relevant\" chunks)\n[OPTIONAL] extracts any potential tags/filters from the question and applies them to filter down the potential candidates (use extract_metadata=true in build_index, you can also provide some filters explicitly via tag_filter)\n[OPTIONAL] re-ranks the candidate chunks (define and provide your own rerank_strategy, eg Cohere ReRank API)\nbuild a context from the closest chunks (use chunks_window_margin to tweak if we include preceding and succeeding chunks as well, see ?build_context for more details)\ngenerate an answer from the closest chunks (use return_all=true to see under the hood and debug your application)","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"You should save the index for later to avoid re-embedding / re-extracting the document chunks!","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"serialize(\"examples/index.jls\", index)\nindex = deserialize(\"examples/index.jls\");","category":"page"},{"location":"example/#Evaluations","page":"Example","title":"Evaluations","text":"","category":"section"},{"location":"example/","page":"Example","title":"Example","text":"However, we want to evaluate the quality of the system. For that, we need a set of questions and answers. Ideally, we would handcraft a set of high-quality Q&A pairs. However, this is time-consuming and expensive. Let's generate them from the chunks in our index!","category":"page"},{"location":"example/#Generate-Q-and-A-pairs","page":"Example","title":"Generate Q&A pairs","text":"","category":"section"},{"location":"example/","page":"Example","title":"Example","text":"We need to provide: chunks and sources (file paths for future reference)","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"evals = build_qa_evals(RT.chunks(index),\n    RT.sources(index);\n    instructions = \"None.\",\n    verbose = true);","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"[ Info: Q&A Sets built! (cost: $0.102)\n","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"[!TIP] In practice, you would review each item in this golden evaluation set (and delete any generic/poor questions). It will determine the future success of your app, so you need to make sure it's good!","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"# Save the evals for later\nJSON3.write(\"examples/evals.json\", evals)\nevals = JSON3.read(\"examples/evals.json\", Vector{RT.QAEvalItem});","category":"page"},{"location":"example/#Explore-one-Q-and-A-pair","page":"Example","title":"Explore one Q&A pair","text":"","category":"section"},{"location":"example/","page":"Example","title":"Example","text":"Let's explore one evals item  it's not the best quality but gives you the idea!","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"evals[1]","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"QAEvalItem:\n source: examples/data/database_style_joins.txt\n context: Database-Style Joins\nIntroduction to joins\nWe often need to combine two or more data sets together to provide a complete picture of the topic we are studying. For example, suppose that we have the following two data sets:\n\njulia> using DataFrames\n question: What is the purpose of joining two or more data sets together?\n answer: The purpose of joining two or more data sets together is to provide a complete picture of the topic being studied.\n","category":"page"},{"location":"example/#Evaluate-this-Q-and-A-pair","page":"Example","title":"Evaluate this Q&A pair","text":"","category":"section"},{"location":"example/","page":"Example","title":"Example","text":"Let's evaluate this QA item with a \"judge model\" (often GPT-4 is used as a judge).","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"# Note: that we used the same question, but generated a different context and answer via `airag`\nctx = airag(index; evals[1].question, return_all = true);\n# ctx is a RAGContext object that keeps all intermediate states of the RAG pipeline for easy evaluation\njudged = aiextract(:RAGJudgeAnswerFromContext;\n    ctx.context,\n    ctx.question,\n    ctx.answer,\n    return_type = RT.JudgeAllScores)\njudged.content","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"Dict{Symbol, Any} with 6 entries:\n  :final_rating => 4.8\n  :clarity => 5\n  :completeness => 4\n  :relevance => 5\n  :consistency => 5\n  :helpfulness => 5","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"We can also run the generation + evaluation in a function (a few more metrics are available, eg, retrieval score):","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"x = run_qa_evals(evals[10], ctx;\n    parameters_dict = Dict(:top_k => 3), verbose = true, model_judge = \"gpt4t\")","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"QAEvalResult:\n source: examples/data/database_style_joins.txt\n context: outerjoin: the output contains rows for values of the key that exist in any of the passed data frames.\nsemijoin: Like an inner join, but output is restricted to columns from the first (left) argument.\n question: What is the difference between outer join and semi join?\n answer: The purpose of joining two or more data sets together is to combine them in order to provide a complete picture or analysis of a specific topic or dataset. By joining data sets, we can combine information from multiple sources to gain more insights and make more informed decisions.\n retrieval_score: 0.0\n retrieval_rank: nothing\n answer_score: 5\n parameters: Dict(:top_k => 3)\n","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"Fortunately, we don't have to do this one by one  let's evaluate all our Q&A pairs at once.","category":"page"},{"location":"example/#Evaluate-the-Whole-Set","page":"Example","title":"Evaluate the Whole Set","text":"","category":"section"},{"location":"example/","page":"Example","title":"Example","text":"Let's run each question & answer through our eval loop in async (we do it only for the first 10 to save time). See the ?airag for which parameters you can tweak, eg, top_k","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"results = asyncmap(evals[1:10]) do qa_item\n    # Generate an answer -- often you want the model_judge to be the highest quality possible, eg, \"GPT-4 Turbo\" (alias \"gpt4t)\n    ctx = airag(index; qa_item.question, return_all = true, verbose = false)\n    # Evaluate the response\n    # Note: you can log key parameters for easier analysis later\n    run_qa_evals(qa_item, ctx; parameters_dict = Dict(:top_k => 3), verbose = false, model_judge = \"gpt4t\")\nend\n## Note that the \"failed\" evals can show as \"nothing\" (failed as in there was some API error or parsing error), so make sure to handle them.\nresults = filter(x->!isnothing(x.answer_score), results);","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"Note: You could also use the vectorized version results = run_qa_evals(index, evals) to evaluate all items at once.","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"\n# Let's take a simple average to calculate our score\n@info \"RAG Evals: $(length(results)) results, Avg. score: $(round(mean(x->x.answer_score, results);digits=1)), Retrieval score: $(100*round(Int,mean(x->x.retrieval_score,results)))%\"","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"[ Info: RAG Evals: 10 results, Avg. score: 4.6, Retrieval score: 100%\n","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"Note: The retrieval score is 100% only because we have two small documents and running on 10 items only. In practice, you would have a much larger document set and a much larger eval set, which would result in a more representative retrieval score.","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"You can also analyze the results in a DataFrame:","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"df = DataFrame(results)","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"<div><div style = \"float: left;\"><span>108 DataFrame</span></div><div style = \"clear: both;\"></div></div><div class = \"data-frame\" style = \"overflow-x: scroll;\"><table class = \"data-frame\" style = \"margin-bottom: 6px;\"><thead><tr class = \"header\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">Row</th><th style = \"text-align: left;\">source</th><th style = \"text-align: left;\">context</th><th style = \"text-align: left;\">question</th><th style = \"text-align: left;\">answer</th><th style = \"text-align: left;\">retrieval_score</th><th style = \"text-align: left;\">retrieval_rank</th><th style = \"text-align: left;\">answer_score</th><th style = \"text-align: left;\">parameters</th></tr><tr class = \"subheader headerLastRow\"><th class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\"></th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"String\" style = \"text-align: left;\">String</th><th title = \"SubString{String}\" style = \"text-align: left;\">SubStrin</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Int64\" style = \"text-align: left;\">Int64</th><th title = \"Float64\" style = \"text-align: left;\">Float64</th><th title = \"Dict{Symbol, Int64}\" style = \"text-align: left;\">Dict</th></tr></thead><tbody><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">1</td><td style = \"text-align: left;\">examples/data/database_style_joins.txt</td><td style = \"text-align: left;\">Database-Style Joins\\nIntroduction to joins\\nWe often need to combine two or more data sets together to provide a complete picture of the topic we are studying. For example, suppose that we have the following two data sets:\\n\\njulia&gt; using DataFrames</td><td style = \"text-align: left;\">What is the purpose of joining two or more data sets together?</td><td style = \"text-align: left;\">The purpose of joining two or more data sets together is to combine the data sets based on a common key and provide a complete picture of the topic being studied.</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: left;\">Dict(:top_k=&gt;3)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">2</td><td style = \"text-align: left;\">examples/data/database_style_joins.txt</td><td style = \"text-align: left;\">julia&gt; people = DataFrame(ID=[20, 40], Name=[&quot;John Doe&quot;, &quot;Jane Doe&quot;])\\n22 DataFrame\\n Row  ID     Name\\n      Int64  String\\n\\n   1     20  John Doe\\n   2     40  Jane Doe</td><td style = \"text-align: left;\">What is the DataFrame called &apos;people&apos; composed of?</td><td style = \"text-align: left;\">The DataFrame called &apos;people&apos; consists of two columns: &apos;ID&apos; and &apos;Name&apos;. The &apos;ID&apos; column contains integers, and the &apos;Name&apos; column contains strings.</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">4.0</td><td style = \"text-align: left;\">Dict(:top_k=&gt;3)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">3</td><td style = \"text-align: left;\">examples/data/database_style_joins.txt</td><td style = \"text-align: left;\">julia&gt; jobs = DataFrame(ID=[20, 40], Job=[&quot;Lawyer&quot;, &quot;Doctor&quot;])\\n22 DataFrame\\n Row  ID     Job\\n      Int64  String\\n\\n   1     20  Lawyer\\n   2     40  Doctor</td><td style = \"text-align: left;\">What are the jobs and IDs listed in the dataframe?</td><td style = \"text-align: left;\">The jobs and IDs listed in the dataframe are as follows:\\n\\nID: 20\\nJob: Lawyer\\n\\nID: 40\\nJob: Doctor</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">4.67</td><td style = \"text-align: left;\">Dict(:top_k=&gt;3)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">4</td><td style = \"text-align: left;\">examples/data/database_style_joins.txt</td><td style = \"text-align: left;\">We might want to work with a larger data set that contains both the names and jobs for each ID. We can do this using the innerjoin function:</td><td style = \"text-align: left;\">How can we combine the names and jobs for each ID in a larger data set?</td><td style = \"text-align: left;\">We can use the `innerjoin` function to combine the names and jobs for each ID in a larger data set.</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">4.33333</td><td style = \"text-align: left;\">Dict(:top_k=&gt;3)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">5</td><td style = \"text-align: left;\">examples/data/database_style_joins.txt</td><td style = \"text-align: left;\">julia&gt; innerjoin(people, jobs, on = :ID)\\n23 DataFrame\\n Row  ID     Name      Job\\n      Int64  String    String\\n\\n   1     20  John Doe  Lawyer\\n   2     40  Jane Doe  Doctor</td><td style = \"text-align: left;\">What is the name of the person with the ID 40 and their job?</td><td style = \"text-align: left;\">The name of the person with the ID 40 is Jane Doe and their job is Doctor.</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">2</td><td style = \"text-align: right;\">4.67</td><td style = \"text-align: left;\">Dict(:top_k=&gt;3)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">6</td><td style = \"text-align: left;\">examples/data/database_style_joins.txt</td><td style = \"text-align: left;\">In relational database theory, this operation is generally referred to as a join. The columns used to determine which rows should be combined during a join are called keys.\\n\\nThe following functions are provided to perform seven kinds of joins:</td><td style = \"text-align: left;\">What are the different kinds of joins?</td><td style = \"text-align: left;\">The different kinds of joins are:\\n\\n1. Inner Join: Returns only the rows that have matching values in both data frames.\\n2. Left Join: Returns all rows from the left data frame and the matching rows from the right data frame.\\n3. Right Join: Returns all rows from the right data frame and the matching rows from the left data frame.\\n4. Full Outer Join: Returns all rows from both data frames and fills in missing values with null.\\n5. Cross Join: Returns the cartesian product of the rows from both data frames.\\n6. Semi Join: Returns only the rows from the left data frame that have matching values in the right data frame.\\n7. Anti Join: Returns only the rows from the left data frame that do not have matching values in the right data frame.</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">4.66667</td><td style = \"text-align: left;\">Dict(:top_k=&gt;3)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">7</td><td style = \"text-align: left;\">examples/data/database_style_joins.txt</td><td style = \"text-align: left;\">innerjoin: the output contains rows for values of the key that exist in all passed data frames.</td><td style = \"text-align: left;\">What does the output of the inner join operation contain?</td><td style = \"text-align: left;\">The output of the inner join operation contains only the rows for values of the key that exist in all passed data frames.</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">5.0</td><td style = \"text-align: left;\">Dict(:top_k=&gt;3)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">8</td><td style = \"text-align: left;\">examples/data/database_style_joins.txt</td><td style = \"text-align: left;\">leftjoin: the output contains rows for values of the key that exist in the first (left) argument, whether or not that value exists in the second (right) argument.</td><td style = \"text-align: left;\">What is the purpose of the left join operation?</td><td style = \"text-align: left;\">The purpose of the left join operation is to combine data from two tables based on a common key, where all rows from the left (first) table are included in the output, regardless of whether there is a match in the right (second) table.</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">4.66667</td><td style = \"text-align: left;\">Dict(:top_k=&gt;3)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">9</td><td style = \"text-align: left;\">examples/data/database_style_joins.txt</td><td style = \"text-align: left;\">rightjoin: the output contains rows for values of the key that exist in the second (right) argument, whether or not that value exists in the first (left) argument.</td><td style = \"text-align: left;\">What is the purpose of the right join operation?</td><td style = \"text-align: left;\">The purpose of the right join operation is to include all the rows from the second (right) argument, regardless of whether a match is found in the first (left) argument.</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">4.67</td><td style = \"text-align: left;\">Dict(:top_k=&gt;3)</td></tr><tr><td class = \"rowNumber\" style = \"font-weight: bold; text-align: right;\">10</td><td style = \"text-align: left;\">examples/data/database_style_joins.txt</td><td style = \"text-align: left;\">outerjoin: the output contains rows for values of the key that exist in any of the passed data frames.\\nsemijoin: Like an inner join, but output is restricted to columns from the first (left) argument.</td><td style = \"text-align: left;\">What is the difference between outer join and semi join?</td><td style = \"text-align: left;\">The difference between outer join and semi join is that outer join includes rows for values of the key that exist in any of the passed data frames, whereas semi join is like an inner join but only outputs columns from the first argument.</td><td style = \"text-align: right;\">1.0</td><td style = \"text-align: right;\">1</td><td style = \"text-align: right;\">4.66667</td><td style = \"text-align: left;\">Dict(:top_k=&gt;3)</td></tr></tbody></table></div>","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"We're done for today!","category":"page"},{"location":"example/#What-would-we-do-next?","page":"Example","title":"What would we do next?","text":"","category":"section"},{"location":"example/","page":"Example","title":"Example","text":"Review your evaluation golden data set and keep only the good items\nPlay with the chunk sizes (maxlength in buildindex) and see how it affects the quality\nExplore using metadata/key filters (extract_metadata=true in build_index)\nAdd filtering for semantic similarity (embedding distance) to make sure we don't pick up irrelevant chunks in the context\nUse multiple indices or a hybrid index (add a simple BM25 lookup from TextAnalysis.jl)\nData processing is the most important step - properly parsed and split text could make wonders\nAdd re-ranking of context (see rerank function, you can use Cohere ReRank API)\nImprove the question embedding (eg, rephrase it, generate hypothetical answers and use them to find better context)","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"... and much more! See some ideas in Anyscale RAG tutorial","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"","category":"page"},{"location":"example/","page":"Example","title":"Example","text":"This page was generated using Literate.jl.","category":"page"}]
}
